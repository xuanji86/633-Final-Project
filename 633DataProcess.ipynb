{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "1af09f7a-ffec-40a5-92c3-6d0e6c6cbd9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "import ast\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import torch\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_sequence\n",
    "from torch.utils.data import DataLoader, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "057b122d-a0eb-4fc5-9c30-39ddddc50d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_train = pd.read_csv('633FinalData/img_train.csv')\n",
    "cgm_train = pd.read_csv('633FinalData/cgm_train.csv')\n",
    "demo_viome_train = pd.read_csv('633FinalData/demo_viome_train.csv')\n",
    "label_train = pd.read_csv('633FinalData/label_train.csv')\n",
    "img_test = pd.read_csv('633FinalData/img_test.csv')\n",
    "cgm_test = pd.read_csv('633FinalData/cgm_test.csv')\n",
    "demo_viome_test= pd.read_csv('633FinalData/demo_viome_test.csv')\n",
    "label_test = pd.read_csv('633FinalData/label_test_breakfast_only.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "da3fb988",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Subject ID</th>\n",
       "      <th>Day</th>\n",
       "      <th>Breakfast Time</th>\n",
       "      <th>Lunch Time</th>\n",
       "      <th>CGM Data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2021-10-02 09:55:00</td>\n",
       "      <td>2021-10-02 13:46:00</td>\n",
       "      <td>[('2021-10-02 09:55:00', 114.68333333333334), ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2021-10-03 09:53:00</td>\n",
       "      <td>2021-10-03 13:46:00</td>\n",
       "      <td>[('2021-10-03 09:50:00', 103.0), ('2021-10-03 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>2021-10-06 09:04:00</td>\n",
       "      <td>2021-10-06 12:36:00</td>\n",
       "      <td>[('2021-10-06 09:00:00', 96.41), ('2021-10-06 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>2021-10-07 08:56:00</td>\n",
       "      <td>2021-10-07 12:32:00</td>\n",
       "      <td>[('2021-10-07 08:50:00', 95.0), ('2021-10-07 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>2021-10-08 09:09:00</td>\n",
       "      <td>2021-10-08 12:36:00</td>\n",
       "      <td>[('2021-10-08 09:00:00', 94.13666666666667), (...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>18</td>\n",
       "      <td>5</td>\n",
       "      <td>2022-04-26 08:30:23</td>\n",
       "      <td>2022-04-26 13:39:53</td>\n",
       "      <td>[('2022-04-26 08:25:00', 142.94), ('2022-04-26...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>18</td>\n",
       "      <td>6</td>\n",
       "      <td>2022-04-27 09:17:34</td>\n",
       "      <td>2022-04-27 13:42:28</td>\n",
       "      <td>[('2022-04-27 09:15:00', 138.28333333333333), ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>18</td>\n",
       "      <td>7</td>\n",
       "      <td>2022-04-28 08:21:45</td>\n",
       "      <td>2022-04-28 14:57:13</td>\n",
       "      <td>[('2022-04-28 08:20:00', 138.65666666666667), ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>18</td>\n",
       "      <td>8</td>\n",
       "      <td>2022-04-29 08:52:06</td>\n",
       "      <td>2022-04-29 13:21:09</td>\n",
       "      <td>[('2022-04-29 08:50:00', 143.71666666666667), ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>18</td>\n",
       "      <td>10</td>\n",
       "      <td>2022-05-01 08:41:47</td>\n",
       "      <td>2022-05-01 13:11:54</td>\n",
       "      <td>[('2022-05-01 08:40:00', 142.65666666666667), ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>73 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Subject ID  Day       Breakfast Time           Lunch Time  \\\n",
       "0            4    2  2021-10-02 09:55:00  2021-10-02 13:46:00   \n",
       "1            4    3  2021-10-03 09:53:00  2021-10-03 13:46:00   \n",
       "2            4    6  2021-10-06 09:04:00  2021-10-06 12:36:00   \n",
       "3            4    7  2021-10-07 08:56:00  2021-10-07 12:32:00   \n",
       "4            4    8  2021-10-08 09:09:00  2021-10-08 12:36:00   \n",
       "..         ...  ...                  ...                  ...   \n",
       "68          18    5  2022-04-26 08:30:23  2022-04-26 13:39:53   \n",
       "69          18    6  2022-04-27 09:17:34  2022-04-27 13:42:28   \n",
       "70          18    7  2022-04-28 08:21:45  2022-04-28 14:57:13   \n",
       "71          18    8  2022-04-29 08:52:06  2022-04-29 13:21:09   \n",
       "72          18   10  2022-05-01 08:41:47  2022-05-01 13:11:54   \n",
       "\n",
       "                                             CGM Data  \n",
       "0   [('2021-10-02 09:55:00', 114.68333333333334), ...  \n",
       "1   [('2021-10-03 09:50:00', 103.0), ('2021-10-03 ...  \n",
       "2   [('2021-10-06 09:00:00', 96.41), ('2021-10-06 ...  \n",
       "3   [('2021-10-07 08:50:00', 95.0), ('2021-10-07 0...  \n",
       "4   [('2021-10-08 09:00:00', 94.13666666666667), (...  \n",
       "..                                                ...  \n",
       "68  [('2022-04-26 08:25:00', 142.94), ('2022-04-26...  \n",
       "69  [('2022-04-27 09:15:00', 138.28333333333333), ...  \n",
       "70  [('2022-04-28 08:20:00', 138.65666666666667), ...  \n",
       "71  [('2022-04-29 08:50:00', 143.71666666666667), ...  \n",
       "72  [('2022-05-01 08:40:00', 142.65666666666667), ...  \n",
       "\n",
       "[73 rows x 5 columns]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cgm_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "c2a30d57-7f2f-49d8-8ba9-3dd4d9dfa101",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_image(image_str):\n",
    "    image_data = ast.literal_eval(image_str)\n",
    "    image_array = np.array(image_data, dtype=np.uint8)\n",
    "    return image_array.astype(np.float32) / 255.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "b6ece9c6-e9e4-4420-b707-1ce9b77be461",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_str(image_str):\n",
    "    image_data = ast.literal_eval(image_str)\n",
    "    image_array = np.array(image_data, dtype=np.float64)\n",
    "    return image_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "749d78ac-7ce3-4e37-b040-500558822283",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_preprocess(img_train,cgm_train,label_train,demo_viome_train):\n",
    "    img_train = img_train.drop('Subject ID', axis=1)\n",
    "    cgm_train = cgm_train.drop('Subject ID', axis=1)\n",
    "    label_train = label_train.drop('Subject ID', axis=1)\n",
    "    demo_viome_train = demo_viome_train.drop('Subject ID', axis=1)\n",
    "    img_train = img_train.drop('Day', axis=1)\n",
    "    cgm_train = cgm_train.drop('Day', axis=1)\n",
    "    label_train = label_train.drop('Day', axis=1)\n",
    "    \n",
    "    repeated_demo_viome_train = demo_viome_train.loc[demo_viome_train.index.repeat(9)].reset_index(drop=True)\n",
    "    \n",
    "    \n",
    "    combined_data = pd.concat([img_train, cgm_train, label_train,repeated_demo_viome_train], axis=1)\n",
    "    combined_data = combined_data.dropna()\n",
    "    \n",
    "    \n",
    "    idx = []\n",
    "    for i in range (combined_data.shape[0]):\n",
    "        for j in range (combined_data.shape[1]):\n",
    "            cell = combined_data.iloc[i, j]\n",
    "            if isinstance(cell, str) and len(cell) == 2:  # Checking string length\n",
    "                idx.append(i)\n",
    "    \n",
    "    combined_data.drop(idx, inplace=True)\n",
    "    \n",
    "    combined_data['Breakfast Time'] = pd.to_datetime(combined_data['Breakfast Time'])\n",
    "    combined_data['Lunch Time'] = pd.to_datetime(combined_data['Lunch Time'])\n",
    "    \n",
    "    combined_data['Breakfast minute'] = combined_data['Breakfast Time'].dt.hour*60+combined_data['Breakfast Time'].dt.minute\n",
    "    combined_data['Lunch minute'] = combined_data['Lunch Time'].dt.hour*60+combined_data['Lunch Time'].dt.minute\n",
    "    \n",
    "    combined_data['cgm_numbers'] = combined_data.iloc[:, 4].apply(lambda x: [float(num) for num in re.findall(r\",\\s([\\d\\.]+)\\)\", x)])\n",
    "    \n",
    "    combined_data['Race'] = pd.Categorical(combined_data['Race'], categories=['Hispanic/Latino', 'White', 'Other'])\n",
    "    \n",
    "    # If needed, convert the categories into numerical codes\n",
    "    combined_data['Race_Categorical'] = combined_data['Race'].cat.codes\n",
    "    \n",
    "    \n",
    "    combined_data = combined_data.drop(['Breakfast Time','Lunch Time','CGM Data','Race'], axis=1)\n",
    "\n",
    "    \n",
    "    \n",
    "    # Print all column names\n",
    "    print(combined_data.columns.tolist())\n",
    "    \n",
    "    \n",
    "    \n",
    "    combined_data['Viome'] = combined_data['Viome'].apply(convert_str)\n",
    "    \n",
    "    img_set = combined_data[['Image Before Breakfast', 'Image Before Lunch']]\n",
    "    rest = combined_data.drop(columns=['Image Before Breakfast', 'Image Before Lunch'])\n",
    "    \n",
    "    \n",
    "    label = combined_data[['Lunch Calories','Lunch Protein','Lunch Carbs','Lunch Fat']]\n",
    "    rest = rest.drop(columns=['Lunch Calories','Lunch Protein','Lunch Carbs','Lunch Fat'])\n",
    "    \n",
    "    catagorical = combined_data[['Gender','Diabetes Status','Race_Categorical']]\n",
    "    rest = rest.drop(columns=['Gender','Diabetes Status','Race_Categorical'])\n",
    "    \n",
    "    time_set  = combined_data[['cgm_numbers','Viome']]\n",
    "    continues = rest.drop(columns=['cgm_numbers','Viome'])\n",
    "    variable_sequence_tensors = [torch.tensor(seq, dtype=torch.float32) for seq in time_set['cgm_numbers']]\n",
    "    fixed_sequence_tensors = torch.tensor(time_set['Viome'].tolist(), dtype=torch.float32)  # Already uniform length\n",
    "    \n",
    "    # Pad the variable-length sequences\n",
    "    padded_variable_sequences = pad_sequence(variable_sequence_tensors, batch_first=True, padding_value=0)\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    img_set['Image Before Breakfast'] = img_set['Image Before Breakfast'].apply(convert_image)\n",
    "    img_set['Image Before Lunch'] = img_set['Image Before Lunch'].apply(convert_image)\n",
    "    \n",
    "    # Convert numpy arrays into tensors and stack them\n",
    "    img_tensors_breakfast = torch.stack([torch.tensor(img) for img in img_set['Image Before Breakfast']])\n",
    "    img_tensors_lunch = torch.stack([torch.tensor(img) for img in img_set['Image Before Lunch']])\n",
    "    \n",
    "    \n",
    "    \n",
    "    scaler = MinMaxScaler()  # Or StandardScaler for standardization\n",
    "    X_train_scaled = scaler.fit_transform(continues)\n",
    "\n",
    "    \n",
    "    \n",
    "    # Ensure labels are numeric and then convert to tensor\n",
    "    label = label.apply(pd.to_numeric, errors='coerce')  # Convert to numeric, coercing errors\n",
    "    label_tensor = torch.tensor(label.values, dtype=torch.float32)\n",
    "    \n",
    "    # Ensure categorical data is numeric and then convert to tensor\n",
    "    catagorical = catagorical.apply(pd.to_numeric, errors='coerce')\n",
    "    catagorical_tensor = torch.tensor(catagorical.values, dtype=torch.float32)\n",
    "    \n",
    "    return img_tensors_breakfast,img_tensors_lunch, label_tensor, catagorical_tensor, padded_variable_sequences, fixed_sequence_tensors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "da9991b3-e95f-43f7-b45c-663f0c0dd3fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Image Before Breakfast', 'Image Before Lunch', 'Breakfast Calories', 'Breakfast Carbs', 'Breakfast Fat', 'Breakfast Protein', 'Age', 'Gender', 'Weight', 'Height', 'Diabetes Status', 'A1C', 'Baseline Fasting Glucose', 'Insulin', 'Triglycerides', 'Cholesterol', 'HDL', 'Non-HDL', 'LDL', 'VLDL', 'CHO/HDL Ratio', 'HOMA-IR', 'BMI', 'Viome', 'Breakfast minute', 'Lunch minute', 'cgm_numbers', 'Race_Categorical']\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"None of [Index(['Lunch Calories', 'Lunch Protein', 'Lunch Carbs', 'Lunch Fat'], dtype='object')] are in the [columns]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[77], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# img_breakfast_train,img_lunch_train, label_train,catagorical_train,padded_variable_sequences_train,fixed_sequence_tensors_train = data_preprocess(img_train,cgm_train,label_train,demo_viome_train)\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m img_breakfast_test,img_lunch_test, label_test,catagorical_test,padded_variable_sequences_test,fixed_sequence_tensors_test \u001b[38;5;241m=\u001b[39m data_preprocess(img_test,cgm_test,label_test,demo_viome_test)\n",
      "Cell \u001b[1;32mIn[76], line 55\u001b[0m, in \u001b[0;36mdata_preprocess\u001b[1;34m(img_train, cgm_train, label_train, demo_viome_train)\u001b[0m\n\u001b[0;32m     51\u001b[0m img_set \u001b[38;5;241m=\u001b[39m combined_data[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mImage Before Breakfast\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mImage Before Lunch\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n\u001b[0;32m     52\u001b[0m rest \u001b[38;5;241m=\u001b[39m combined_data\u001b[38;5;241m.\u001b[39mdrop(columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mImage Before Breakfast\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mImage Before Lunch\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m---> 55\u001b[0m label \u001b[38;5;241m=\u001b[39m combined_data[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLunch Calories\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLunch Protein\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLunch Carbs\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLunch Fat\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n\u001b[0;32m     56\u001b[0m rest \u001b[38;5;241m=\u001b[39m rest\u001b[38;5;241m.\u001b[39mdrop(columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLunch Calories\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLunch Protein\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLunch Carbs\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLunch Fat\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     58\u001b[0m catagorical \u001b[38;5;241m=\u001b[39m combined_data[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGender\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDiabetes Status\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRace_Categorical\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\ML\\Lib\\site-packages\\pandas\\core\\frame.py:4108\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4106\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[0;32m   4107\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[1;32m-> 4108\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39m_get_indexer_strict(key, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m   4110\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[0;32m   4111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\ML\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6200\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[1;34m(self, key, axis_name)\u001b[0m\n\u001b[0;32m   6197\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   6198\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[1;32m-> 6200\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_if_missing(keyarr, indexer, axis_name)\n\u001b[0;32m   6202\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[0;32m   6203\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[0;32m   6204\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\ML\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6249\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[1;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[0;32m   6247\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m nmissing:\n\u001b[0;32m   6248\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m nmissing \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(indexer):\n\u001b[1;32m-> 6249\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   6251\u001b[0m     not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[0;32m   6252\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"None of [Index(['Lunch Calories', 'Lunch Protein', 'Lunch Carbs', 'Lunch Fat'], dtype='object')] are in the [columns]\""
     ]
    }
   ],
   "source": [
    "# img_breakfast_train,img_lunch_train, label_train,catagorical_train,padded_variable_sequences_train,fixed_sequence_tensors_train = data_preprocess(img_train,cgm_train,label_train,demo_viome_train)\n",
    "img_breakfast_test,img_lunch_test, label_test,catagorical_test,padded_variable_sequences_test,fixed_sequence_tensors_test = data_preprocess(img_test,cgm_test,label_test,demo_viome_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9428324c-4121-42b8-9234-a5e298180308",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, img_breakfast,img_lunch, labels, categoricals, sequences, fixed_sequences):\n",
    "        self.img_breakfast = img_breakfast\n",
    "        self.img_lunch = img_breakfast\n",
    "        self.labels = labels\n",
    "        self.categoricals = categoricals\n",
    "        self.sequences = sequences\n",
    "        self.fixed_sequences = fixed_sequences\n",
    "\n",
    "    def __len__(self):\n",
    "        # Assuming all tensors have the same first dimension size\n",
    "        return len(self.img_breakfast)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Fetch each tensor's slice at the given index\n",
    "        return {\n",
    "            'breakfast_images': self.img_breakfast[idx],\n",
    "            'lunch_images': self.img_lunch[idx],\n",
    "            'labels': self.labels[idx],\n",
    "            'categoricals': self.categoricals[idx],\n",
    "            'sequences': self.sequences[idx],\n",
    "            'fixed_sequences': self.fixed_sequences[idx]\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f022d3cd-8ac7-4eed-8c1e-46086dc14fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assume tensors have already been defined as img_tensors, label_tensor, etc.\n",
    "train_dataset = CustomDataset(img_breakfast_train,img_lunch_train, label_train,catagorical_train,padded_variable_sequences_train,fixed_sequence_tensors_train)\n",
    "\n",
    "# Define DataLoader with batch size, shuffling, etc.\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=4)\n",
    "\n",
    "\n",
    "# test_dataset = CustomDataset(img_breakfast_test,img_lunch_test, label_test,catagorical_train,padded_variable_sequences_train,fixed_sequence_tensors_train)\n",
    "\n",
    "# # Define DataLoader with batch size, shuffling, etc.\n",
    "# train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e63de1a-173d-4cd5-acfc-b2526195acae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
