{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1af09f7a-ffec-40a5-92c3-6d0e6c6cbd9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "import ast\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import torch\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_sequence\n",
    "from torch.utils.data import DataLoader, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "057b122d-a0eb-4fc5-9c30-39ddddc50d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_train = pd.read_csv('633FinalData/img_train.csv')\n",
    "cgm_train = pd.read_csv('633FinalData/cgm_train.csv')\n",
    "demo_viome_train = pd.read_csv('633FinalData/demo_viome_train.csv')\n",
    "label_train = pd.read_csv('633FinalData/label_train.csv')\n",
    "img_test = pd.read_csv('633FinalData/img_test.csv')\n",
    "cgm_test = pd.read_csv('633FinalData/cgm_test.csv')\n",
    "demo_viome_test= pd.read_csv('633FinalData/demo_viome_test.csv')\n",
    "label_test = pd.read_csv('633FinalData/label_test_breakfast_only.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c2a30d57-7f2f-49d8-8ba9-3dd4d9dfa101",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_image(image_str):\n",
    "    image_data = ast.literal_eval(image_str)\n",
    "    image_array = np.array(image_data, dtype=np.uint8)\n",
    "    return image_array.astype(np.float32) / 255.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b6ece9c6-e9e4-4420-b707-1ce9b77be461",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_str(image_str):\n",
    "    image_data = ast.literal_eval(image_str)\n",
    "    image_array = np.array(image_data, dtype=np.float64)\n",
    "    return image_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "749d78ac-7ce3-4e37-b040-500558822283",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_preprocess(img_train,cgm_train,label_train,demo_viome_train,train=0):\n",
    "    img_train = img_train.drop('Subject ID', axis=1)\n",
    "    cgm_train = cgm_train.drop('Subject ID', axis=1)\n",
    "    label_train = label_train.drop('Subject ID', axis=1)\n",
    "    demo_viome_train = demo_viome_train.drop('Subject ID', axis=1)\n",
    "    img_train = img_train.drop('Day', axis=1)\n",
    "    cgm_train = cgm_train.drop('Day', axis=1)\n",
    "    label_train = label_train.drop('Day', axis=1)\n",
    "    \n",
    "    repeated_demo_viome_train = demo_viome_train.loc[demo_viome_train.index.repeat(9)].reset_index(drop=True)\n",
    "    \n",
    "    \n",
    "    combined_data = pd.concat([img_train, cgm_train, label_train,repeated_demo_viome_train], axis=1)\n",
    "    combined_data = combined_data.dropna()\n",
    "    \n",
    "    idx = []\n",
    "    for i in range (combined_data.shape[0]):\n",
    "        for j in range (combined_data.shape[1]):\n",
    "            cell = combined_data.iloc[i, j]\n",
    "            if isinstance(cell, str) and len(cell) == 2:  # Checking string length\n",
    "                idx.append(i)\n",
    "    \n",
    "    combined_data.drop(idx, inplace=True)\n",
    "    \n",
    "    combined_data['Breakfast Time'] = pd.to_datetime(combined_data['Breakfast Time'])\n",
    "    combined_data['Lunch Time'] = pd.to_datetime(combined_data['Lunch Time'])\n",
    "    \n",
    "    combined_data['Breakfast minute'] = combined_data['Breakfast Time'].dt.hour*60+combined_data['Breakfast Time'].dt.minute\n",
    "    combined_data['Lunch minute'] = combined_data['Lunch Time'].dt.hour*60+combined_data['Lunch Time'].dt.minute\n",
    "    \n",
    "    combined_data['cgm_numbers'] = combined_data.iloc[:, 4].apply(lambda x: [float(num) for num in re.findall(r\",\\s([\\d\\.]+)\\)\", x)])\n",
    "    \n",
    "    combined_data['Race'] = pd.Categorical(combined_data['Race'], categories=['Hispanic/Latino', 'White', 'Other'])\n",
    "    \n",
    "    # If needed, convert the categories into numerical codes\n",
    "    combined_data['Race_Categorical'] = combined_data['Race'].cat.codes\n",
    "    \n",
    "    \n",
    "    combined_data = combined_data.drop(['Breakfast Time','Lunch Time','CGM Data','Race'], axis=1)\n",
    "    \n",
    "    # Print all column names\n",
    "    print(combined_data.columns.tolist())\n",
    "    \n",
    "    \n",
    "    \n",
    "    combined_data['Viome'] = combined_data['Viome'].apply(convert_str)\n",
    "    \n",
    "    img_set = combined_data[['Image Before Breakfast', 'Image Before Lunch']]\n",
    "    rest = combined_data.drop(columns=['Image Before Breakfast', 'Image Before Lunch'])\n",
    "    \n",
    "    if train:\n",
    "        label = combined_data[['Lunch Calories','Lunch Protein','Lunch Carbs','Lunch Fat']]\n",
    "        rest = rest.drop(columns=['Lunch Calories','Lunch Protein','Lunch Carbs','Lunch Fat'])\n",
    "    \n",
    "    catagorical = combined_data[['Gender','Diabetes Status','Race_Categorical']]\n",
    "    rest = rest.drop(columns=['Gender','Diabetes Status','Race_Categorical'])\n",
    "    \n",
    "    time_set  = combined_data[['cgm_numbers','Viome']]\n",
    "    continues = rest.drop(columns=['cgm_numbers','Viome'])\n",
    "    variable_sequence_tensors = [torch.tensor(seq, dtype=torch.float32) for seq in time_set['cgm_numbers']]\n",
    "    fixed_sequence_tensors = torch.tensor(time_set['Viome'].tolist(), dtype=torch.float32)  # Already uniform length\n",
    "    \n",
    "    # Pad the variable-length sequences\n",
    "    padded_variable_sequences = pad_sequence(variable_sequence_tensors, batch_first=True, padding_value=0)\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    img_set['Image Before Breakfast'] = img_set['Image Before Breakfast'].apply(convert_image)\n",
    "    img_set['Image Before Lunch'] = img_set['Image Before Lunch'].apply(convert_image)\n",
    "    \n",
    "    # Convert numpy arrays into tensors and stack them\n",
    "    img_tensors_breakfast = torch.stack([torch.tensor(img) for img in img_set['Image Before Breakfast']])\n",
    "    img_tensors_lunch = torch.stack([torch.tensor(img) for img in img_set['Image Before Lunch']])\n",
    "    \n",
    "    \n",
    "    \n",
    "    scaler = MinMaxScaler()  # Or StandardScaler for standardization\n",
    "    X_train_scaled = scaler.fit_transform(continues)\n",
    "\n",
    "    \n",
    "    if train:\n",
    "        # Ensure labels are numeric and then convert to tensor\n",
    "        label = label.apply(pd.to_numeric, errors='coerce')  # Convert to numeric, coercing errors\n",
    "        label_tensor = torch.tensor(label.values, dtype=torch.float32)\n",
    "    \n",
    "    # Ensure categorical data is numeric and then convert to tensor\n",
    "    catagorical = catagorical.apply(pd.to_numeric, errors='coerce')\n",
    "    catagorical_tensor = torch.tensor(catagorical.values, dtype=torch.float32)\n",
    "\n",
    "    if train:\n",
    "        return img_tensors_breakfast,img_tensors_lunch, label_tensor, catagorical_tensor, padded_variable_sequences, fixed_sequence_tensors\n",
    "    else:\n",
    "        return img_tensors_breakfast,img_tensors_lunch, catagorical_tensor, padded_variable_sequences, fixed_sequence_tensors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "da9991b3-e95f-43f7-b45c-663f0c0dd3fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Image Before Breakfast', 'Image Before Lunch', 'Breakfast Calories', 'Lunch Calories', 'Breakfast Carbs', 'Lunch Carbs', 'Breakfast Fat', 'Lunch Fat', 'Breakfast Protein', 'Lunch Protein', 'Age', 'Gender', 'Weight', 'Height', 'Diabetes Status', 'A1C', 'Baseline Fasting Glucose', 'Insulin', 'Triglycerides', 'Cholesterol', 'HDL', 'Non-HDL', 'LDL', 'VLDL', 'CHO/HDL Ratio', 'HOMA-IR', 'BMI', 'Viome', 'Breakfast minute', 'Lunch minute', 'cgm_numbers', 'Race_Categorical']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/rw/2ymm_dx14vvcsj7zgnrlwphw0000gn/T/ipykernel_69223/3691393194.py:71: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  img_set['Image Before Breakfast'] = img_set['Image Before Breakfast'].apply(convert_image)\n",
      "/var/folders/rw/2ymm_dx14vvcsj7zgnrlwphw0000gn/T/ipykernel_69223/3691393194.py:72: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  img_set['Image Before Lunch'] = img_set['Image Before Lunch'].apply(convert_image)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Image Before Breakfast', 'Image Before Lunch', 'Breakfast Calories', 'Breakfast Carbs', 'Breakfast Fat', 'Breakfast Protein', 'Age', 'Gender', 'Weight', 'Height', 'Diabetes Status', 'A1C', 'Baseline Fasting Glucose', 'Insulin', 'Triglycerides', 'Cholesterol', 'HDL', 'Non-HDL', 'LDL', 'VLDL', 'CHO/HDL Ratio', 'HOMA-IR', 'BMI', 'Viome', 'Breakfast minute', 'Lunch minute', 'cgm_numbers', 'Race_Categorical']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/rw/2ymm_dx14vvcsj7zgnrlwphw0000gn/T/ipykernel_69223/3691393194.py:71: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  img_set['Image Before Breakfast'] = img_set['Image Before Breakfast'].apply(convert_image)\n",
      "/var/folders/rw/2ymm_dx14vvcsj7zgnrlwphw0000gn/T/ipykernel_69223/3691393194.py:72: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  img_set['Image Before Lunch'] = img_set['Image Before Lunch'].apply(convert_image)\n"
     ]
    }
   ],
   "source": [
    "img_breakfast_train,img_lunch_train, label_train,catagorical_train,padded_variable_sequences_train,fixed_sequence_tensors_train = data_preprocess(img_train,cgm_train,label_train,demo_viome_train,train=1)\n",
    "img_breakfast_test,img_lunch_test, catagorical_test,padded_variable_sequences_test,fixed_sequence_tensors_test = data_preprocess(img_test,cgm_test,label_test,demo_viome_test,train=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9428324c-4121-42b8-9234-a5e298180308",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomTrainDataset(Dataset):\n",
    "    def __init__(self, img_breakfast,img_lunch, labels, categoricals, sequences, fixed_sequences):\n",
    "        self.img_breakfast = img_breakfast\n",
    "        self.img_lunch = img_breakfast\n",
    "        self.labels = labels\n",
    "        self.categoricals = categoricals\n",
    "        self.sequences = sequences\n",
    "        self.fixed_sequences = fixed_sequences\n",
    "\n",
    "    def __len__(self):\n",
    "        # Assuming all tensors have the same first dimension size\n",
    "        return len(self.img_breakfast)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Fetch each tensor's slice at the given index\n",
    "        return {\n",
    "            'breakfast_images': self.img_breakfast[idx],\n",
    "            'lunch_images': self.img_lunch[idx],\n",
    "            'labels': self.labels[idx],\n",
    "            'categoricals': self.categoricals[idx],\n",
    "            'sequences': self.sequences[idx],\n",
    "            'fixed_sequences': self.fixed_sequences[idx]\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d52e6ff6-3f13-42dc-a1c2-9bd074c32038",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomTestDataset(Dataset):\n",
    "    def __init__(self, img_breakfast,img_lunch, categoricals, sequences, fixed_sequences):\n",
    "        self.img_breakfast = img_breakfast\n",
    "        self.img_lunch = img_breakfast\n",
    "        self.categoricals = categoricals\n",
    "        self.sequences = sequences\n",
    "        self.fixed_sequences = fixed_sequences\n",
    "\n",
    "    def __len__(self):\n",
    "        # Assuming all tensors have the same first dimension size\n",
    "        return len(self.img_breakfast)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Fetch each tensor's slice at the given index\n",
    "        return {\n",
    "            'breakfast_images': self.img_breakfast[idx],\n",
    "            'lunch_images': self.img_lunch[idx],\n",
    "            'categoricals': self.categoricals[idx],\n",
    "            'sequences': self.sequences[idx],\n",
    "            'fixed_sequences': self.fixed_sequences[idx]\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f022d3cd-8ac7-4eed-8c1e-46086dc14fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assume tensors have already been defined as img_tensors, label_tensor, etc.\n",
    "train_dataset = CustomTrainDataset(img_breakfast_train,img_lunch_train, label_train,catagorical_train,padded_variable_sequences_train,fixed_sequence_tensors_train)\n",
    "\n",
    "# Define DataLoader with batch size, shuffling, etc.\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=4)\n",
    "\n",
    "\n",
    "test_dataset = CustomTestDataset(img_breakfast_test,img_lunch_test, catagorical_train,padded_variable_sequences_train,fixed_sequence_tensors_train)\n",
    "\n",
    "# Define DataLoader with batch size, shuffling, etc.\n",
    "test_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e63de1a-173d-4cd5-acfc-b2526195acae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
