{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1af09f7a-ffec-40a5-92c3-6d0e6c6cbd9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "import ast\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import torch\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_sequence\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "057b122d-a0eb-4fc5-9c30-39ddddc50d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_train = pd.read_csv('633FinalData/img_train.csv')\n",
    "cgm_train = pd.read_csv('633FinalData/cgm_train.csv')\n",
    "demo_viome_train = pd.read_csv('633FinalData/demo_viome_train.csv')\n",
    "label_train = pd.read_csv('633FinalData/label_train.csv')\n",
    "img_test = pd.read_csv('633FinalData/img_test.csv')\n",
    "cgm_test = pd.read_csv('633FinalData/cgm_test.csv')\n",
    "demo_viome_test= pd.read_csv('633FinalData/demo_viome_test.csv')\n",
    "label_test = pd.read_csv('633FinalData/label_test_breakfast_only.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c2a30d57-7f2f-49d8-8ba9-3dd4d9dfa101",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_image(image_str):\n",
    "    image_data = ast.literal_eval(image_str)\n",
    "    image_array = np.array(image_data, dtype=np.uint8)\n",
    "    return image_array.astype(np.float32) / 255.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b6ece9c6-e9e4-4420-b707-1ce9b77be461",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_str(image_str):\n",
    "    image_data = ast.literal_eval(image_str)\n",
    "    image_array = np.array(image_data, dtype=np.float64)\n",
    "    return image_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "36d92808-fe3c-48de-953a-fcd53e30b243",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_time(step):\n",
    "    time_bar = np.zeros((288, 1))\n",
    "    time_bar[step - 1, 0] = 1\n",
    "    return time_bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d5886f62-2971-4c50-a73a-a8eadc7dd5e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_global = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "749d78ac-7ce3-4e37-b040-500558822283",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_preprocess(img_train,cgm_train,label_train,demo_viome_train,train=0):\n",
    "    img_train = img_train.drop('Subject ID', axis=1)\n",
    "    cgm_train = cgm_train.drop('Subject ID', axis=1)\n",
    "    label_train = label_train.drop('Subject ID', axis=1)\n",
    "    demo_viome_train = demo_viome_train.drop('Subject ID', axis=1)\n",
    "    img_train = img_train.drop('Day', axis=1)\n",
    "    cgm_train = cgm_train.drop('Day', axis=1)\n",
    "    label_train = label_train.drop('Day', axis=1)\n",
    "    \n",
    "    repeated_demo_viome_train = demo_viome_train.loc[demo_viome_train.index.repeat(9)].reset_index(drop=True)\n",
    "    \n",
    "    \n",
    "    combined_data = pd.concat([img_train, cgm_train, label_train,repeated_demo_viome_train], axis=1)\n",
    "    combined_data = combined_data.dropna()\n",
    "    \n",
    "    idx = []\n",
    "    for i in range (combined_data.shape[0]):\n",
    "        for j in range (combined_data.shape[1]):\n",
    "            cell = combined_data.iloc[i, j]\n",
    "            if isinstance(cell, str) and len(cell) == 2:  # Checking string length\n",
    "                idx.append(i)\n",
    "    \n",
    "    combined_data.drop(idx, inplace=True)\n",
    "    if train:   \n",
    "        combined_data['Breakfast Time'] = pd.to_datetime(combined_data['Breakfast Time'])\n",
    "        \n",
    "        combined_data['Step'] = np.round((combined_data['Breakfast Time'].dt.hour*60+combined_data['Breakfast Time'].dt.minute)/5).astype(int)\n",
    "        combined_data['Breakfast minute'] = combined_data['Step'].apply(get_time)\n",
    "\n",
    "        combined_data['Lunch Time'] = pd.to_datetime(combined_data['Lunch Time'])\n",
    "        combined_data['Step'] = np.round((combined_data['Lunch Time'].dt.hour*60+combined_data['Lunch Time'].dt.minute)/5).astype(int)\n",
    "        combined_data['Lunch minute'] = combined_data['Step'].apply(get_time)\n",
    "    \n",
    "    \n",
    "    else:\n",
    "        combined_data['Breakfast Time'] = pd.to_datetime(combined_data['Breakfast Time'])     \n",
    "        combined_data['Step'] = np.round((combined_data['Breakfast Time'].dt.hour*60+combined_data['Breakfast Time'].dt.minute)/5).astype(int)\n",
    "        combined_data['Breakfast minute'] = combined_data['Step'].apply(get_time)\n",
    "    \n",
    "        \n",
    "    combined_data['cgm_numbers'] = combined_data['CGM Data'].apply(lambda x: [float(num) for num in re.findall(r\",\\s([\\d\\.]+)\\)\", x)])\n",
    "\n",
    "\n",
    "    combined_data['gcm_start'] = combined_data['CGM Data'].apply(lambda x: ast.literal_eval(x)[0][0])\n",
    "\n",
    "    combined_data['gcm_start_step']  = ((combined_data['gcm_start'].astype('datetime64[ns]').dt.hour*60  + combined_data['gcm_start'].astype('datetime64[ns]').dt.minute)/5).astype(int)\n",
    "    \n",
    "    combined_data['repeated_front'] = combined_data.apply(lambda row: [row['cgm_numbers'][0]] * row['gcm_start_step']+ row['cgm_numbers'][1:],axis=1)\n",
    "    \n",
    "    \n",
    "    combined_data['gcm_number_bar'] = combined_data.apply(lambda row: row['repeated_front'][:-1] + [row['repeated_front'][-1]] * (289-len(row['repeated_front'])),axis=1)\n",
    "    \n",
    "    combined_data['Race'] = pd.Categorical(combined_data['Race'], categories=['Hispanic/Latino', 'White', 'Other'])\n",
    "    \n",
    "    # If needed, convert the categories into numerical codes\n",
    "    combined_data['Race_Categorical'] = combined_data['Race'].cat.codes\n",
    "    \n",
    "    \n",
    "    combined_data = combined_data.drop(['Step','Breakfast Time','Lunch Time','CGM Data','Race','Step','cgm_numbers','gcm_start','gcm_start_step','repeated_front'], axis=1)\n",
    "    \n",
    "    # Print all column names\n",
    "    print(combined_data.columns.tolist())\n",
    "    \n",
    "    \n",
    "    \n",
    "    combined_data['Viome'] = combined_data['Viome'].apply(convert_str)\n",
    "    if train:\n",
    "        img_b = combined_data[['Image Before Breakfast']]\n",
    "\n",
    "        img_l = combined_data[['Image Before Lunch']]\n",
    "        rest = combined_data.drop(columns=['Image Before Breakfast', 'Image Before Lunch'])\n",
    "    else:\n",
    "        img_b = combined_data[['Image Before Breakfast']]\n",
    "\n",
    "        rest = combined_data.drop(columns=['Image Before Breakfast', 'Image Before Lunch'])\n",
    "    \n",
    "    if train:\n",
    "        label_b = combined_data[['Breakfast Calories']]\n",
    "\n",
    "        label_l = combined_data[['Lunch Calories']]\n",
    "        rest = rest.drop(columns=['Breakfast Calories', 'Lunch Calories', 'Breakfast Carbs',\n",
    "                                  'Lunch Carbs', 'Breakfast Fat', 'Lunch Fat',\n",
    "                                  'Breakfast Protein', 'Lunch Protein',])\n",
    "    else:\n",
    "        label_b = combined_data[['Breakfast Calories']]\n",
    "        rest = rest.drop(columns=['Breakfast Calories', 'Breakfast Carbs','Breakfast Fat', \n",
    "                                  'Breakfast Protein'])\n",
    "        \n",
    "\n",
    "    \n",
    "    catagorical = combined_data[['Gender','Diabetes Status','Race_Categorical']]\n",
    "    rest = rest.drop(columns=['Gender','Diabetes Status','Race_Categorical'])\n",
    "\n",
    "    if train:       \n",
    "        time_set  = combined_data[['gcm_number_bar','Viome','Breakfast minute']]\n",
    "        time_set_l = combined_data[['Lunch minute']]\n",
    "        continues = rest.drop(columns=['gcm_number_bar','Viome','Breakfast minute','Lunch minute'])\n",
    "    else:\n",
    "        time_set  = combined_data[['gcm_number_bar','Viome','Breakfast minute']]\n",
    "        continues = rest.drop(columns=['gcm_number_bar','Viome','Breakfast minute'])\n",
    "    scaler1 = MinMaxScaler()  # Or StandardScaler for standardization\n",
    "    scaler2 = MinMaxScaler()\n",
    "    scaler3 = MinMaxScaler()\n",
    "    scaler4 = MinMaxScaler()\n",
    "    scaler5 = MinMaxScaler()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    ###\n",
    "    # Convert list of sequences to a NumPy array\n",
    "    gcm_number_array = np.array(time_set['gcm_number_bar'].tolist())      \n",
    "    # Fit and transform the array\n",
    "    scaled_gcm_number_array = scaler1.fit_transform(gcm_number_array)\n",
    "    gcm_number_tensors = torch.tensor(scaled_gcm_number_array, dtype=torch.float32)\n",
    "\n",
    "\n",
    "    \n",
    "    Viome_array = np.array(time_set['Viome'].tolist())      \n",
    "    # Fit and transform the array\n",
    "    scaled_Viome_sequences = scaler2.fit_transform(Viome_array)\n",
    "    Viome_tensors = torch.tensor(scaled_Viome_sequences, dtype=torch.float32)\n",
    "\n",
    "    if train:        \n",
    "        minute_array = np.array(time_set['Breakfast minute'].tolist())\n",
    "        minute_array = minute_array.reshape(-1,288)\n",
    "        # print(minute_array.shape)\n",
    "        # Fit and transform the array\n",
    "        scaled_minute_array = scaler3.fit_transform(minute_array)\n",
    "        minute_tensors = torch.tensor(scaled_minute_array, dtype=torch.float32)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        minute_array_l = np.array(time_set_l['Lunch minute'].tolist())\n",
    "        minute_array_l = minute_array_l.reshape(-1,288)\n",
    "        # print(minute_array.shape)\n",
    "        # Fit and transform the array\n",
    "        scaled_minute_l_array = scaler3.fit_transform(minute_array_l)\n",
    "        minute_l_tensors = torch.tensor(scaled_minute_l_array, dtype=torch.float32)\n",
    "    else:\n",
    "        minute_array = np.array(time_set['Breakfast minute'].tolist())      \n",
    "        # Fit and transform the array\n",
    "        minute_array = minute_array.reshape(-1,288)\n",
    "        scaled_minute_array = scaler3.fit_transform(minute_array)\n",
    "        minute_tensors = torch.tensor(scaled_minute_array, dtype=torch.float32)\n",
    "    \n",
    "    # Convert the scaled array back to a tensor\n",
    "\n",
    "\n",
    "    \n",
    "    # Pad the variable-length sequences\n",
    "\n",
    "    # print(len(fixed_sequence_tensors[0]))\n",
    "    # print(len(padded_variable_sequences[0]))\n",
    "\n",
    "    \n",
    "\n",
    "    if train:  \n",
    "        img_b['Image Before Breakfast'] = img_b['Image Before Breakfast'].apply(convert_image)\n",
    "        # img_set['Image Before Lunch'] = img_set['Image Before Lunch'].apply(convert_image)    \n",
    "        # Convert numpy arrays into tensors and stack them\n",
    "        img_b_tensors = torch.stack([torch.tensor(img) for img in img_b['Image Before Breakfast']])\n",
    "        # img_tensors_lunch = torch.stack([torch.tensor(img) for img in img_set['Image Before Lunch']])\n",
    "\n",
    "\n",
    "        img_l['Image Before Lunch'] = img_l['Image Before Lunch'].apply(convert_image)\n",
    "        # img_set['Image Before Lunch'] = img_set['Image Before Lunch'].apply(convert_image)    \n",
    "        # Convert numpy arrays into tensors and stack them\n",
    "        img_l_tensors = torch.stack([torch.tensor(img) for img in img_l['Image Before Lunch']])\n",
    "        # img_tensors_lunch = torch.stack([torch.tensor(img) for img in img_set['Image Before Lunch']])\n",
    "    else:\n",
    "        img_b['Image Before Breakfast'] = img_b['Image Before Breakfast'].apply(convert_image)\n",
    "        # img_set['Image Before Lunch'] = img_set['Image Before Lunch'].apply(convert_image)    \n",
    "        # Convert numpy arrays into tensors and stack them\n",
    "        img_b_tensors = torch.stack([torch.tensor(img) for img in img_b['Image Before Breakfast']])\n",
    "        # img_tensors_lunch = torch.stack([torch.tensor(img) for img in img_set['Image Before Lunch']])\n",
    "    \n",
    "    \n",
    "\n",
    "    continuous_scaled = scaler4.fit_transform(continues)\n",
    "    continuous_tensor = torch.tensor(continuous_scaled, dtype=torch.float32)\n",
    "\n",
    "        \n",
    "    if train:\n",
    "        # Ensure labels are numeric and then convert to tensor\n",
    "        label_l = label_l.apply(pd.to_numeric, errors='coerce')  # Convert to numeric, coercing errors\n",
    "        print(label_l.shape)\n",
    "        label_l_scaled = scaler_global.fit_transform(label_l)\n",
    "        label_l_tensor = torch.tensor(label_l_scaled, dtype=torch.float32)\n",
    "\n",
    "    label_b = label_b.apply(pd.to_numeric, errors='coerce')  # Convert to numeric, coercing errors\n",
    "    label_b_scaled = scaler5.fit_transform(label_b)\n",
    "    label_b_tensor = torch.tensor(label_b_scaled, dtype=torch.float32)\n",
    "\n",
    "    # Ensure categorical data is numeric and then convert to tensor\n",
    "    catagorical = catagorical.apply(pd.to_numeric, errors='coerce')\n",
    "    catagorical_tensor = torch.tensor(catagorical.values, dtype=torch.float32)\n",
    "    \n",
    "    # print(len(continuous_tensor[0]))\n",
    "    # print(len(catagorical_tensor[0]))\n",
    "    # print(img_tensors_breakfast[0].shape)\n",
    "    # print(img_tensors_lunch[0].shape)\n",
    "\n",
    "    if train:\n",
    "        return img_b_tensors,minute_tensors,gcm_number_tensors,Viome_tensors, catagorical_tensor, continuous_tensor,label_b_tensor,label_l_tensor,img_l_tensors,minute_l_tensors\n",
    "    else:\n",
    "        return img_b_tensors,minute_tensors,gcm_number_tensors,Viome_tensors, catagorical_tensor, continuous_tensor,label_b_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "da9991b3-e95f-43f7-b45c-663f0c0dd3fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Image Before Breakfast', 'Image Before Lunch', 'Breakfast Calories', 'Lunch Calories', 'Breakfast Carbs', 'Lunch Carbs', 'Breakfast Fat', 'Lunch Fat', 'Breakfast Protein', 'Lunch Protein', 'Age', 'Gender', 'Weight', 'Height', 'Diabetes Status', 'A1C', 'Baseline Fasting Glucose', 'Insulin', 'Triglycerides', 'Cholesterol', 'HDL', 'Non-HDL', 'LDL', 'VLDL', 'CHO/HDL Ratio', 'HOMA-IR', 'BMI', 'Viome', 'Breakfast minute', 'Lunch minute', 'gcm_number_bar', 'Race_Categorical']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/s5/r9sflpf90879qgsm6l5st6640000gs/T/ipykernel_17383/2603920482.py:161: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  img_b['Image Before Breakfast'] = img_b['Image Before Breakfast'].apply(convert_image)\n",
      "/var/folders/s5/r9sflpf90879qgsm6l5st6640000gs/T/ipykernel_17383/2603920482.py:168: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  img_l['Image Before Lunch'] = img_l['Image Before Lunch'].apply(convert_image)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(271, 1)\n",
      "['Image Before Breakfast', 'Image Before Lunch', 'Breakfast Calories', 'Breakfast Carbs', 'Breakfast Fat', 'Breakfast Protein', 'Age', 'Gender', 'Weight', 'Height', 'Diabetes Status', 'A1C', 'Baseline Fasting Glucose', 'Insulin', 'Triglycerides', 'Cholesterol', 'HDL', 'Non-HDL', 'LDL', 'VLDL', 'CHO/HDL Ratio', 'HOMA-IR', 'BMI', 'Viome', 'Breakfast minute', 'gcm_number_bar', 'Race_Categorical']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/s5/r9sflpf90879qgsm6l5st6640000gs/T/ipykernel_17383/2603920482.py:174: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  img_b['Image Before Breakfast'] = img_b['Image Before Breakfast'].apply(convert_image)\n"
     ]
    }
   ],
   "source": [
    "img_b_train,minute_b_train,gcm_number_train,Viome_train, catagorical_train, continuous_train,label_b_train,label_l_train,img_l_train,minute_l_train= data_preprocess(img_train,cgm_train,label_train,demo_viome_train,train=1)\n",
    "img_b_test,minute_b_test,gcm_number_test,Viome_test, catagorical_test, continuous_test,label_b_test= data_preprocess(img_test,cgm_test,label_test,demo_viome_test,train=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9428324c-4121-42b8-9234-a5e298180308",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomTrainDataset(Dataset):\n",
    "    def __init__(self,img_b_train,minute_b_train,gcm_number_train,\n",
    "                 Viome_train, catagorical_train, continuous_train,\n",
    "                 label_b_train,label_l_train,img_l_train,\n",
    "                 minute_l_train):\n",
    "        \n",
    "        self.catagorical_train = np.vstack([catagorical_train,catagorical_train])\n",
    "        self.gcm_number_train =  np.vstack([gcm_number_train,gcm_number_train])\n",
    "        self.continuous_train = np.vstack([continuous_train,continuous_train])\n",
    "        self.Viome_train = np.vstack([Viome_train,Viome_train])\n",
    "\n",
    "        \n",
    "        self.minute_train = np.vstack([minute_b_train,minute_l_train])\n",
    "        self.img_train = np.vstack([img_b_train,img_l_train])\n",
    "        \n",
    "        \n",
    "        self.label = np.vstack([label_b_train,label_l_train])\n",
    "\n",
    "    \n",
    "    def __len__(self):\n",
    "        # Assuming all tensors have the same first dimension size\n",
    "        return len(self.img_train)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Fetch each tensor's slice at the given index\n",
    "        return {\n",
    "            'img': self.img_train[idx],\n",
    "            'catagorical': self.catagorical_train[idx],\n",
    "            'minute_train': self.minute_train[idx],\n",
    "            'gcm_number_train': self.gcm_number_train[idx],\n",
    "            'Viome_train': self.Viome_train[idx],\n",
    "            'continuous': self.continuous_train[idx],\n",
    "            'label': self.label[idx],\n",
    "\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d52e6ff6-3f13-42dc-a1c2-9bd074c32038",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomTestDataset(Dataset):\n",
    "    def __init__(self, img_b_train,minute_b_train,gcm_number_train,\n",
    "                 Viome_train, catagorical_train, continuous_train,\n",
    "                 label_b_train):\n",
    "        self.img_train = img_b_train\n",
    "        self.catagorical_train = catagorical_train\n",
    "        self.minute_train = minute_b_train\n",
    "        self.gcm_number_train = gcm_number_train\n",
    "        self.Viome_train = Viome_train\n",
    "        self.continuous_train = continuous_train\n",
    "        self.label = label_b_train\n",
    "\n",
    "\n",
    "    \n",
    "    def __len__(self):\n",
    "        # Assuming all tensors have the same first dimension size\n",
    "        return len(self.img_train)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Fetch each tensor's slice at the given index\n",
    "        return {\n",
    "            'img': self.img_train[idx],\n",
    "            'catagorical': self.catagorical_train[idx],\n",
    "            'minute_train': self.minute_train[idx],\n",
    "            'gcm_number_train': self.gcm_number_train[idx],\n",
    "            'Viome_train': self.Viome_train[idx],\n",
    "            'continuous': self.continuous_train[idx],\n",
    "            'label': self.label[idx]\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f022d3cd-8ac7-4eed-8c1e-46086dc14fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assume tensors have already been defined as img_tensors, label_tensor, etc.\n",
    "train_dataset = CustomTrainDataset(img_b_train,minute_b_train,gcm_number_train,Viome_train, catagorical_train, continuous_train,label_b_train,label_l_train,img_l_train,minute_l_train)\n",
    "\n",
    "# Define DataLoader with batch size, shuffling, etc.\n",
    "train_loader = DataLoader(train_dataset, batch_size=73, shuffle=True, num_workers=0,drop_last=True)\n",
    "\n",
    "\n",
    "test_dataset = CustomTestDataset(img_b_test,minute_b_test,gcm_number_test,Viome_test, catagorical_test, continuous_test,label_b_test)\n",
    "\n",
    "# Define DataLoader with batch size, shuffling, etc.\n",
    "test_loader = DataLoader(train_dataset, batch_size=73, shuffle=True, num_workers=0,drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5e63de1a-173d-4cd5-acfc-b2526195acae",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultimodalModel(nn.Module):\n",
    "    def __init__(self, image_model_name=\"resnet18\", fusion_dim=512):\n",
    "        super(MultimodalModel, self).__init__()\n",
    "\n",
    "        # Image Encoder\n",
    "        self.image_model = models.resnet18(pretrained=True)\n",
    "        self.image_model.fc = nn.Linear(self.image_model.fc.in_features, 128)\n",
    "\n",
    "        # Time-Series Encoder\n",
    "        self.lstm1 = nn.LSTM(input_size=27, hidden_size=128, num_layers=73, batch_first=True)#fixed for 1\n",
    "        self.lstm2 = nn.LSTM(input_size=288, hidden_size=128, num_layers=73, batch_first=True)\n",
    "\n",
    "        # Tabular Data Encoder\n",
    "        self.cata_fc = nn.Sequential(\n",
    "            nn.Linear(3, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(64, 128)\n",
    "        )\n",
    "        self.conti_fc = nn.Sequential(\n",
    "            nn.Linear(15, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(64, 128)\n",
    "        )\n",
    "\n",
    "        # Fusion Layer\n",
    "        self.fusion_fc = nn.Sequential(\n",
    "            nn.Linear(128 + 128 + 128 + 128 + 128 + 128, fusion_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(fusion_dim, 128),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        # Regression Head\n",
    "        self.regressor = nn.Sequential(\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 1),  # Single output for calorie prediction\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, image, time_series_1,time_series_2,time_series_3, catagotical, continous):\n",
    "        # Process each modality\n",
    "        image = image.permute(0, 3, 1, 2)  # Reorder from [batch, height, width, channels] to [batch, channels, height, width]\n",
    "        img_feat = self.image_model(image)\n",
    "        _, (time_feat_1, _) = self.lstm2(time_series_1)\n",
    "        _, (time_feat_2, _) = self.lstm2(time_series_2)\n",
    "        _, (time_feat_3, _) = self.lstm1(time_series_3)\n",
    "        # time_feat_1 = time_feat_1[-1]  # Last hidden state\n",
    "        # time_feat_2 = time_feat_2[-1]  # Last hidden state\n",
    "        cat_feat = self.cata_fc(catagotical)\n",
    "        conti_feat = self.conti_fc(continous)\n",
    "\n",
    "\n",
    "        \n",
    "        # print(f\"img_feat_l: {img_feat_l.shape}\")\n",
    "        # print(f\"img_feat_b: {img_feat_b.shape}\")\n",
    "        # print(f\"time_feat_1: {time_feat_1.shape}\")\n",
    "        # print(f\"time_feat_2: {time_feat_2.shape}\")\n",
    "        # print(f\"cat_feat: {cat_feat.shape}\")\n",
    "        # print(f\"conti_feat: {conti_feat.shape}\")\n",
    "\n",
    "        # Fuse features\n",
    "        fused = torch.cat([img_feat, time_feat_1,time_feat_2,time_feat_3, cat_feat,conti_feat], dim=1)\n",
    "        fusion_out = self.fusion_fc(fused)\n",
    "\n",
    "        # Predict\n",
    "        output = self.regressor(fusion_out)\n",
    "        return output\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8fd5e6a1-4d2e-4f61-bf19-dfa832b8a702",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/calzheng/.local/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/calzheng/.local/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "model = MultimodalModel(\n",
    "    image_model_name=\"resnet18\",\n",
    "    fusion_dim=512\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7453b34c-c48f-4b7c-a657-3987d5000a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RMSRELoss(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(RMSRELoss, self).__init__()\n",
    "\n",
    "    def forward(self, y_pred, y_true):\n",
    "        # Ensure no division by zero\n",
    "        relative_error = (y_pred - y_true) / (y_true + 1e-8)  # Add epsilon for numerical stability\n",
    "        return torch.sqrt(torch.mean(relative_error ** 2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "601a9db1-5c17-43e1-8cdb-02ffc3c0cde2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, test_loader, criterion):\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    total_loss = 0.0\n",
    "    total_rmse = 0.0\n",
    "    total_rmsre = 0.0\n",
    "    num_batches = 0\n",
    "\n",
    "    with torch.no_grad():  # Disable gradient computation for testing\n",
    "        for data in test_loader:\n",
    "            images = data['img']\n",
    "            label_b = data['label_b']\n",
    "            categoricals = data['catagorical']\n",
    "            minute = data['minute_train']\n",
    "            gcm_number = data['gcm_number_train']\n",
    "            Viome = data['Viome_train']\n",
    "            continuous = data['continuous']\n",
    "            label = data['label']\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(images,minute,gcm_number, Viome, categoricals, continuous)\n",
    "            loss = criterion(outputs, label)  # Compute loss\n",
    "\n",
    "            # Compute RMSE\n",
    "            rmse = torch.sqrt(torch.mean((outputs - label) ** 2))\n",
    "\n",
    "            relative_error = (outputs - label) / (outputs + 1e-8)  # Add epsilon for numerical stability\n",
    "            rmsre = torch.sqrt(torch.mean(relative_error ** 2))\n",
    "\n",
    "            # Accumulate metrics\n",
    "            total_loss += loss.item()\n",
    "            total_rmse += rmse.item()\n",
    "            total_rmsre += rmsre.item()\n",
    "            num_batches += 1\n",
    "\n",
    "    # Average metrics over all batches\n",
    "    avg_loss = total_loss / num_batches\n",
    "    avg_rmse = total_rmse / num_batches\n",
    "    avg_rmsre = total_rmse / num_batches\n",
    "\n",
    "    return avg_loss, avg_rmse, avg_rmsre "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "981116ab-0353-4f52-80be-67e376d66b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RMSRELoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(RMSRELoss, self).__init__()\n",
    "\n",
    "    def forward(self, y_pred, y_true):\n",
    "        # Compute relative error\n",
    "        relative_error = (y_pred - y_true) / (y_true + 1e-8)  # Avoid division by zero\n",
    "        # Compute RMSRE\n",
    "        rmsre = torch.sqrt(torch.mean(relative_error ** 2))\n",
    "        return rmsre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ba7d72-57af-4d8c-9ec5-16de5db361ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = RMSRELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001, weight_decay=1e-4)\n",
    "\n",
    "# # Train the model\n",
    "# trained_model = train_model(model, dataloaders, criterion, optimizer, num_epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d8820e5-6075-4284-856e-f705c40493db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9afc397c-0fee-41ca-9f3f-76a7eaee86c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb0c0893-86f4-4a73-a4fe-90a77219879b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0005], grad_fn=<SelectBackward0>)\n",
      "tensor([0.2424])\n",
      "tensor([0.0038], grad_fn=<SelectBackward0>)\n",
      "tensor([0.5758])\n",
      "tensor([5.3204e-12], grad_fn=<SelectBackward0>)\n",
      "tensor([0.])\n",
      "tensor([0.0271], grad_fn=<SelectBackward0>)\n",
      "tensor([0.2424])\n",
      "tensor([1.7796e-05], grad_fn=<SelectBackward0>)\n",
      "tensor([1.])\n",
      "tensor([0.0094], grad_fn=<SelectBackward0>)\n",
      "tensor([1.])\n",
      "tensor([2.5312e-08], grad_fn=<SelectBackward0>)\n",
      "tensor([0.])\n",
      "Epoch [1/2000], Loss: 1663.7218\n",
      "tensor([7.8024e-09], grad_fn=<SelectBackward0>)\n",
      "tensor([0.])\n",
      "tensor([0.0105], grad_fn=<SelectBackward0>)\n",
      "tensor([0.7003])\n",
      "tensor([0.0366], grad_fn=<SelectBackward0>)\n",
      "tensor([0.2424])\n",
      "tensor([0.0010], grad_fn=<SelectBackward0>)\n",
      "tensor([0.5363])\n",
      "tensor([0.0542], grad_fn=<SelectBackward0>)\n",
      "tensor([0.2839])\n",
      "tensor([0.0169], grad_fn=<SelectBackward0>)\n",
      "tensor([0.2424])\n",
      "tensor([7.1257e-05], grad_fn=<SelectBackward0>)\n",
      "tensor([1.])\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 2000\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    for data in train_loader:\n",
    "        images = data['img']\n",
    "        categoricals = data['catagorical']\n",
    "        minute = data['minute_train']\n",
    "        gcm_number = data['gcm_number_train']\n",
    "        Viome = data['Viome_train']\n",
    "        continuous = data['continuous']\n",
    "        label = data['label']\n",
    "        # print(gcm_number.shape)\n",
    "        # Forward pass\n",
    "        outputs = model(images,minute,gcm_number, Viome, categoricals, continuous)\n",
    "        loss = criterion(outputs, label)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3fada30-3a87-425b-9c80-9a57ce85bad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, test_loader):\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    \n",
    "\n",
    "    with torch.no_grad():  # Disable gradient computation for testing\n",
    "        for data in test_loader:\n",
    "            images = data['img']\n",
    "            categoricals = data['catagorical']\n",
    "            minute = data['minute_train']\n",
    "            gcm_number = data['gcm_number_train']\n",
    "            Viome = data['Viome_train']\n",
    "            continuous = data['continuous']\n",
    "            label = data['label']\n",
    "\n",
    "            # Forward pass\n",
    "    outputs = model(images,minute,gcm_number, Viome, categoricals, continuous)\n",
    "    Prediction = scaler_global.inverse_transform(outputs.detach().numpy())\n",
    "\n",
    "\n",
    "    return Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b871643-dfac-4682-97ba-a5b62e235f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs  = predict(model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e71202ad-2c67-4f14-a458-e678b586b1f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e34872-0485-4513-a745-1e9c42daf079",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['row_id'] = range(73)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b76972c7-494e-4842-82d6-a1ccb1ee1cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(outputs, columns=['Column1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f92e77d8-a3ce-44f9-9501-f2b579cd7041",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to CSV\n",
    "df.to_csv('my_data.csv', index=True)  # index=False means do not write row names (index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f94f0a4-5a73-4646-8ffb-22c8b2267bad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
