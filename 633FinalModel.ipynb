{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "1af09f7a-ffec-40a5-92c3-6d0e6c6cbd9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "import ast\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import torch\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_sequence\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "057b122d-a0eb-4fc5-9c30-39ddddc50d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_train = pd.read_csv('633FinalData/img_train.csv')\n",
    "cgm_train = pd.read_csv('633FinalData/cgm_train.csv')\n",
    "demo_viome_train = pd.read_csv('633FinalData/demo_viome_train.csv')\n",
    "label_train = pd.read_csv('633FinalData/label_train.csv')\n",
    "img_test = pd.read_csv('633FinalData/img_test.csv')\n",
    "cgm_test = pd.read_csv('633FinalData/cgm_test.csv')\n",
    "demo_viome_test= pd.read_csv('633FinalData/demo_viome_test.csv')\n",
    "label_test = pd.read_csv('633FinalData/label_test_breakfast_only.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c2a30d57-7f2f-49d8-8ba9-3dd4d9dfa101",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_image(image_str):\n",
    "    image_data = ast.literal_eval(image_str)\n",
    "    image_array = np.array(image_data, dtype=np.uint8)\n",
    "    return image_array.astype(np.float32) / 255.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b6ece9c6-e9e4-4420-b707-1ce9b77be461",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_str(image_str):\n",
    "    image_data = ast.literal_eval(image_str)\n",
    "    image_array = np.array(image_data, dtype=np.float64)\n",
    "    return image_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "36d92808-fe3c-48de-953a-fcd53e30b243",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_time(step):\n",
    "    time_bar = np.zeros((288, 1))\n",
    "    time_bar[step - 1, 0] = 1\n",
    "    return time_bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "d5886f62-2971-4c50-a73a-a8eadc7dd5e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_global = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "749d78ac-7ce3-4e37-b040-500558822283",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_preprocess(img_train,cgm_train,label_train,demo_viome_train,train=0):\n",
    "    img_train = img_train.drop('Subject ID', axis=1)\n",
    "    cgm_train = cgm_train.drop('Subject ID', axis=1)\n",
    "    label_train = label_train.drop('Subject ID', axis=1)\n",
    "    demo_viome_train = demo_viome_train.drop('Subject ID', axis=1)\n",
    "    img_train = img_train.drop('Day', axis=1)\n",
    "    cgm_train = cgm_train.drop('Day', axis=1)\n",
    "    label_train = label_train.drop('Day', axis=1)\n",
    "    \n",
    "    repeated_demo_viome_train = demo_viome_train.loc[demo_viome_train.index.repeat(9)].reset_index(drop=True)\n",
    "    \n",
    "    \n",
    "    combined_data = pd.concat([img_train, cgm_train, label_train,repeated_demo_viome_train], axis=1)\n",
    "    combined_data = combined_data.dropna()\n",
    "    \n",
    "    idx = []\n",
    "    for i in range (combined_data.shape[0]):\n",
    "        for j in range (combined_data.shape[1]):\n",
    "            cell = combined_data.iloc[i, j]\n",
    "            if isinstance(cell, str) and len(cell) == 2:  # Checking string length\n",
    "                idx.append(i)\n",
    "    \n",
    "    combined_data.drop(idx, inplace=True)\n",
    "    if train:   \n",
    "        combined_data['Breakfast Time'] = pd.to_datetime(combined_data['Breakfast Time'])\n",
    "        \n",
    "        combined_data['Step'] = np.round((combined_data['Breakfast Time'].dt.hour*60+combined_data['Breakfast Time'].dt.minute)/5).astype(int)\n",
    "        combined_data['Breakfast minute'] = combined_data['Step'].apply(get_time)\n",
    "\n",
    "        combined_data['Lunch Time'] = pd.to_datetime(combined_data['Lunch Time'])\n",
    "        combined_data['Step'] = np.round((combined_data['Lunch Time'].dt.hour*60+combined_data['Lunch Time'].dt.minute)/5).astype(int)\n",
    "        combined_data['Lunch minute'] = combined_data['Step'].apply(get_time)\n",
    "    \n",
    "    \n",
    "    else:\n",
    "        combined_data['Breakfast Time'] = pd.to_datetime(combined_data['Breakfast Time'])     \n",
    "        combined_data['Step'] = np.round((combined_data['Breakfast Time'].dt.hour*60+combined_data['Breakfast Time'].dt.minute)/5).astype(int)\n",
    "        combined_data['Breakfast minute'] = combined_data['Step'].apply(get_time)\n",
    "    \n",
    "        \n",
    "    combined_data['cgm_numbers'] = combined_data['CGM Data'].apply(lambda x: [float(num) for num in re.findall(r\",\\s([\\d\\.]+)\\)\", x)])\n",
    "\n",
    "\n",
    "    combined_data['gcm_start'] = combined_data['CGM Data'].apply(lambda x: ast.literal_eval(x)[0][0])\n",
    "\n",
    "    combined_data['gcm_start_step']  = ((combined_data['gcm_start'].astype('datetime64[ns]').dt.hour*60  + combined_data['gcm_start'].astype('datetime64[ns]').dt.minute)/5).astype(int)\n",
    "    \n",
    "    combined_data['repeated_front'] = combined_data.apply(lambda row: [row['cgm_numbers'][0]] * row['gcm_start_step']+ row['cgm_numbers'][1:],axis=1)\n",
    "    \n",
    "    \n",
    "    combined_data['gcm_number_bar'] = combined_data.apply(lambda row: row['repeated_front'][:-1] + [row['repeated_front'][-1]] * (289-len(row['repeated_front'])),axis=1)\n",
    "    \n",
    "    combined_data['Race'] = pd.Categorical(combined_data['Race'], categories=['Hispanic/Latino', 'White', 'Other'])\n",
    "    \n",
    "    # If needed, convert the categories into numerical codes\n",
    "    combined_data['Race_Categorical'] = combined_data['Race'].cat.codes\n",
    "    \n",
    "    \n",
    "    combined_data = combined_data.drop(['Step','Breakfast Time','Lunch Time','CGM Data','Race','Step','cgm_numbers','gcm_start','gcm_start_step','repeated_front'], axis=1)\n",
    "    \n",
    "    # Print all column names\n",
    "    print(combined_data.columns.tolist())\n",
    "    \n",
    "    \n",
    "    \n",
    "    combined_data['Viome'] = combined_data['Viome'].apply(convert_str)\n",
    "    if train:\n",
    "        img_b = combined_data[['Image Before Breakfast']]\n",
    "\n",
    "        img_l = combined_data[['Image Before Lunch']]\n",
    "        rest = combined_data.drop(columns=['Image Before Breakfast', 'Image Before Lunch'])\n",
    "    else:\n",
    "        img_b = combined_data[['Image Before Breakfast']]\n",
    "\n",
    "        rest = combined_data.drop(columns=['Image Before Breakfast', 'Image Before Lunch'])\n",
    "    \n",
    "    if train:\n",
    "        label_b = combined_data[['Breakfast Calories']]\n",
    "\n",
    "        label_l = combined_data[['Lunch Calories']]\n",
    "        rest = rest.drop(columns=['Breakfast Calories', 'Lunch Calories', 'Breakfast Carbs',\n",
    "                                  'Lunch Carbs', 'Breakfast Fat', 'Lunch Fat',\n",
    "                                  'Breakfast Protein', 'Lunch Protein',])\n",
    "    else:\n",
    "        label_b = combined_data[['Breakfast Calories']]\n",
    "        rest = rest.drop(columns=['Breakfast Calories', 'Breakfast Carbs','Breakfast Fat', \n",
    "                                  'Breakfast Protein'])\n",
    "        \n",
    "\n",
    "    \n",
    "    catagorical = combined_data[['Gender','Diabetes Status','Race_Categorical']]\n",
    "    rest = rest.drop(columns=['Gender','Diabetes Status','Race_Categorical'])\n",
    "\n",
    "    if train:       \n",
    "        time_set  = combined_data[['gcm_number_bar','Viome','Breakfast minute']]\n",
    "        time_set_l = combined_data[['Lunch minute']]\n",
    "        continues = rest.drop(columns=['gcm_number_bar','Viome','Breakfast minute','Lunch minute'])\n",
    "    else:\n",
    "        time_set  = combined_data[['gcm_number_bar','Viome','Breakfast minute']]\n",
    "        continues = rest.drop(columns=['gcm_number_bar','Viome','Breakfast minute'])\n",
    "    scaler1 = MinMaxScaler()  # Or StandardScaler for standardization\n",
    "    scaler2 = MinMaxScaler()\n",
    "    scaler3 = MinMaxScaler()\n",
    "    scaler4 = MinMaxScaler()\n",
    "    scaler5 = MinMaxScaler()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    ###\n",
    "    # Convert list of sequences to a NumPy array\n",
    "    gcm_number_array = np.array(time_set['gcm_number_bar'].tolist())  \n",
    "    gcm_number_array = gcm_number_array.reshape(-1,288)\n",
    "    # Fit and transform the array\n",
    "    scaled_gcm_number_array = scaler1.fit_transform(gcm_number_array)\n",
    "    scaled_gcm_number_array_expand = np.expand_dims(scaled_gcm_number_array, axis=-1)\n",
    "    gcm_number_tensors = torch.tensor(scaled_gcm_number_array_expand, dtype=torch.float32)\n",
    "\n",
    "\n",
    "    \n",
    "    Viome_array = np.array(time_set['Viome'].tolist())\n",
    "    # Fit and transform the array\n",
    "    scaled_Viome_sequences = scaler2.fit_transform(Viome_array)\n",
    "    scaled_Viome_sequences_expand = np.expand_dims(scaled_Viome_sequences, axis=-1)\n",
    "    Viome_tensors = torch.tensor(scaled_Viome_sequences_expand, dtype=torch.float32)\n",
    "\n",
    "    if train:        \n",
    "        minute_array = np.array(time_set['Breakfast minute'].tolist())\n",
    "        minute_array = minute_array.reshape(-1,288)\n",
    "        # print(minute_array.shape)\n",
    "        # Fit and transform the array\n",
    "        scaled_minute_array = scaler3.fit_transform(minute_array)\n",
    "        scaled_minute_array_expand = np.expand_dims(scaled_minute_array, axis=-1)\n",
    "        minute_tensors = torch.tensor(scaled_minute_array_expand, dtype=torch.float32)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        minute_array_l = np.array(time_set_l['Lunch minute'].tolist())\n",
    "        minute_array_l = minute_array_l.reshape(-1,288)\n",
    "        # print(minute_array.shape)\n",
    "        # Fit and transform the array\n",
    "        scaled_minute_l_array = scaler3.fit_transform(minute_array_l)\n",
    "        scaled_minute_l_array_expand = np.expand_dims(scaled_minute_l_array, axis=-1)\n",
    "        minute_l_tensors = torch.tensor(scaled_minute_l_array_expand, dtype=torch.float32)\n",
    "    else:\n",
    "        minute_array = np.array(time_set['Breakfast minute'].tolist())      \n",
    "        # Fit and transform the array\n",
    "        minute_array = minute_array.reshape(-1,288)\n",
    "        scaled_minute_array = scaler3.fit_transform(minute_array)\n",
    "        scaled_minute_array_expand = np.expand_dims(scaled_minute_array, axis=-1)\n",
    "        minute_tensors = torch.tensor(scaled_minute_array_expand, dtype=torch.float32)\n",
    "    \n",
    "    # Convert the scaled array back to a tensor\n",
    "\n",
    "\n",
    "    \n",
    "    # Pad the variable-length sequences\n",
    "\n",
    "    # print(len(fixed_sequence_tensors[0]))\n",
    "    # print(len(padded_variable_sequences[0]))\n",
    "\n",
    "    \n",
    "\n",
    "    if train:  \n",
    "        img_b['Image Before Breakfast'] = img_b['Image Before Breakfast'].apply(convert_image)\n",
    "        # img_set['Image Before Lunch'] = img_set['Image Before Lunch'].apply(convert_image)    \n",
    "        # Convert numpy arrays into tensors and stack them\n",
    "        img_b_tensors = torch.stack([torch.tensor(img) for img in img_b['Image Before Breakfast']])\n",
    "        # img_tensors_lunch = torch.stack([torch.tensor(img) for img in img_set['Image Before Lunch']])\n",
    "\n",
    "\n",
    "        img_l['Image Before Lunch'] = img_l['Image Before Lunch'].apply(convert_image)\n",
    "        # img_set['Image Before Lunch'] = img_set['Image Before Lunch'].apply(convert_image)    \n",
    "        # Convert numpy arrays into tensors and stack them\n",
    "        img_l_tensors = torch.stack([torch.tensor(img) for img in img_l['Image Before Lunch']])\n",
    "        # img_tensors_lunch = torch.stack([torch.tensor(img) for img in img_set['Image Before Lunch']])\n",
    "    else:\n",
    "        img_b['Image Before Breakfast'] = img_b['Image Before Breakfast'].apply(convert_image)\n",
    "        # img_set['Image Before Lunch'] = img_set['Image Before Lunch'].apply(convert_image)    \n",
    "        # Convert numpy arrays into tensors and stack them\n",
    "        img_b_tensors = torch.stack([torch.tensor(img) for img in img_b['Image Before Breakfast']])\n",
    "        # img_tensors_lunch = torch.stack([torch.tensor(img) for img in img_set['Image Before Lunch']])\n",
    "    \n",
    "    \n",
    "\n",
    "    continuous_scaled = scaler4.fit_transform(continues)\n",
    "    continuous_tensor = torch.tensor(continuous_scaled, dtype=torch.float32)\n",
    "\n",
    "        \n",
    "    if train:\n",
    "        # Ensure labels are numeric and then convert to tensor\n",
    "        label_l = label_l.apply(pd.to_numeric, errors='coerce')  # Convert to numeric, coercing errors\n",
    "        print(label_l.shape)\n",
    "        label_l_scaled = scaler_global.fit_transform(label_l)\n",
    "        label_l_tensor = torch.tensor(label_l_scaled, dtype=torch.float32)\n",
    "\n",
    "    label_b = label_b.apply(pd.to_numeric, errors='coerce')  # Convert to numeric, coercing errors\n",
    "    label_b_scaled = scaler5.fit_transform(label_b)\n",
    "    label_b_tensor = torch.tensor(label_b_scaled, dtype=torch.float32)\n",
    "\n",
    "    # Ensure categorical data is numeric and then convert to tensor\n",
    "    catagorical = catagorical.apply(pd.to_numeric, errors='coerce')\n",
    "    catagorical_tensor = torch.tensor(catagorical.values, dtype=torch.float32)\n",
    "    \n",
    "    # print(len(continuous_tensor[0]))\n",
    "    # print(len(catagorical_tensor[0]))\n",
    "    # print(img_tensors_breakfast[0].shape)\n",
    "    # print(img_tensors_lunch[0].shape)\n",
    "\n",
    "    if train:\n",
    "        return img_b_tensors,minute_tensors,gcm_number_tensors,Viome_tensors, catagorical_tensor, continuous_tensor,label_b_tensor,label_l_tensor,img_l_tensors,minute_l_tensors\n",
    "    else:\n",
    "        return img_b_tensors,minute_tensors,gcm_number_tensors,Viome_tensors, catagorical_tensor, continuous_tensor,label_b_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "da9991b3-e95f-43f7-b45c-663f0c0dd3fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Image Before Breakfast', 'Image Before Lunch', 'Breakfast Calories', 'Lunch Calories', 'Breakfast Carbs', 'Lunch Carbs', 'Breakfast Fat', 'Lunch Fat', 'Breakfast Protein', 'Lunch Protein', 'Age', 'Gender', 'Weight', 'Height', 'Diabetes Status', 'A1C', 'Baseline Fasting Glucose', 'Insulin', 'Triglycerides', 'Cholesterol', 'HDL', 'Non-HDL', 'LDL', 'VLDL', 'CHO/HDL Ratio', 'HOMA-IR', 'BMI', 'Viome', 'Breakfast minute', 'Lunch minute', 'gcm_number_bar', 'Race_Categorical']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\38997\\AppData\\Local\\Temp\\ipykernel_6964\\236630948.py:167: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  img_b['Image Before Breakfast'] = img_b['Image Before Breakfast'].apply(convert_image)\n",
      "C:\\Users\\38997\\AppData\\Local\\Temp\\ipykernel_6964\\236630948.py:174: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  img_l['Image Before Lunch'] = img_l['Image Before Lunch'].apply(convert_image)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(271, 1)\n",
      "['Image Before Breakfast', 'Image Before Lunch', 'Breakfast Calories', 'Breakfast Carbs', 'Breakfast Fat', 'Breakfast Protein', 'Age', 'Gender', 'Weight', 'Height', 'Diabetes Status', 'A1C', 'Baseline Fasting Glucose', 'Insulin', 'Triglycerides', 'Cholesterol', 'HDL', 'Non-HDL', 'LDL', 'VLDL', 'CHO/HDL Ratio', 'HOMA-IR', 'BMI', 'Viome', 'Breakfast minute', 'gcm_number_bar', 'Race_Categorical']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\38997\\AppData\\Local\\Temp\\ipykernel_6964\\236630948.py:180: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  img_b['Image Before Breakfast'] = img_b['Image Before Breakfast'].apply(convert_image)\n"
     ]
    }
   ],
   "source": [
    "img_b_train,minute_b_train,gcm_number_train,Viome_train, catagorical_train, continuous_train,label_b_train,label_l_train,img_l_train,minute_l_train= data_preprocess(img_train,cgm_train,label_train,demo_viome_train,train=1)\n",
    "img_b_test,minute_b_test,gcm_number_test,Viome_test, catagorical_test, continuous_test,label_b_test= data_preprocess(img_test,cgm_test,label_test,demo_viome_test,train=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4b407f14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([271, 288])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minute_b_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "9428324c-4121-42b8-9234-a5e298180308",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomTrainDataset(Dataset):\n",
    "    def __init__(self,img_b_train,minute_b_train,gcm_number_train,\n",
    "                 Viome_train, catagorical_train, continuous_train,\n",
    "                 label_b_train,label_l_train,img_l_train,\n",
    "                 minute_l_train):\n",
    "        \n",
    "        self.catagorical_train = np.vstack([catagorical_train,catagorical_train])\n",
    "        self.gcm_number_train =  np.vstack([gcm_number_train,gcm_number_train])\n",
    "        self.continuous_train = np.vstack([continuous_train,continuous_train])\n",
    "        self.Viome_train = np.vstack([Viome_train,Viome_train])\n",
    "\n",
    "        \n",
    "        self.minute_train = np.vstack([minute_b_train,minute_l_train])\n",
    "        self.img_train = np.vstack([img_b_train,img_l_train])\n",
    "        \n",
    "        \n",
    "        self.label = np.vstack([label_b_train,label_l_train])\n",
    "\n",
    "    \n",
    "    def __len__(self):\n",
    "        # Assuming all tensors have the same first dimension size\n",
    "        return len(self.img_train)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Fetch each tensor's slice at the given index\n",
    "        return {\n",
    "            'img': self.img_train[idx],\n",
    "            'catagorical': self.catagorical_train[idx],\n",
    "            'minute_train': self.minute_train[idx],\n",
    "            'gcm_number_train': self.gcm_number_train[idx],\n",
    "            'Viome_train': self.Viome_train[idx],\n",
    "            'continuous': self.continuous_train[idx],\n",
    "            'label': self.label[idx],\n",
    "\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "85044a1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([271, 288, 1])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gcm_number_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "d52e6ff6-3f13-42dc-a1c2-9bd074c32038",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomTestDataset(Dataset):\n",
    "    def __init__(self, img_b_train,minute_b_train,gcm_number_train,\n",
    "                 Viome_train, catagorical_train, continuous_train,\n",
    "                 label_b_train):\n",
    "        self.img_train = img_b_train\n",
    "        self.catagorical_train = catagorical_train\n",
    "        self.minute_train = minute_b_train\n",
    "        self.gcm_number_train = gcm_number_train\n",
    "        self.Viome_train = Viome_train\n",
    "        self.continuous_train = continuous_train\n",
    "        self.label = label_b_train\n",
    "\n",
    "\n",
    "    \n",
    "    def __len__(self):\n",
    "        # Assuming all tensors have the same first dimension size\n",
    "        return len(self.img_train)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Fetch each tensor's slice at the given index\n",
    "        return {\n",
    "            'img': self.img_train[idx],\n",
    "            'catagorical': self.catagorical_train[idx],\n",
    "            'minute_train': self.minute_train[idx],\n",
    "            'gcm_number_train': self.gcm_number_train[idx],\n",
    "            'Viome_train': self.Viome_train[idx],\n",
    "            'continuous': self.continuous_train[idx],\n",
    "            'label': self.label[idx]\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "f022d3cd-8ac7-4eed-8c1e-46086dc14fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assume tensors have already been defined as img_tensors, label_tensor, etc.\n",
    "train_dataset = CustomTrainDataset(img_b_train,minute_b_train,gcm_number_train,Viome_train, catagorical_train, continuous_train,label_b_train,label_l_train,img_l_train,minute_l_train)\n",
    "\n",
    "# Define DataLoader with batch size, shuffling, etc.\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=0,drop_last=True)\n",
    "\n",
    "\n",
    "test_dataset = CustomTestDataset(img_b_test,minute_b_test,gcm_number_test,Viome_test, catagorical_test, continuous_test,label_b_test)\n",
    "\n",
    "# Define DataLoader with batch size, shuffling, etc.\n",
    "test_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=0,drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "5e63de1a-173d-4cd5-acfc-b2526195acae",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultimodalModel(nn.Module):\n",
    "    def __init__(self, image_model_name=\"resnet18\", fusion_dim=512):\n",
    "        super(MultimodalModel, self).__init__()\n",
    "\n",
    "        # Image Encoder\n",
    "        self.image_model = models.resnet18(pretrained=True)\n",
    "        self.image_model.fc = nn.Linear(self.image_model.fc.in_features, 128)\n",
    "\n",
    "        # Time-Series Encoder\n",
    "        # self.lstm1 = nn.LSTM(input_size=27, hidden_size=128, num_layers=73, batch_first=True)#fixed for 1\n",
    "        # self.lstm2 = nn.LSTM(input_size=288, hidden_size=128, num_layers=73, batch_first=True)\n",
    "        self.lstm1 = nn.LSTM(input_size=1, hidden_size=128, num_layers=3, batch_first=True)#fixed for 1\n",
    "        self.lstm2 = nn.LSTM(input_size=1, hidden_size=128, num_layers=3, batch_first=True)\n",
    "\n",
    "        # Tabular Data Encoder\n",
    "        self.cata_fc = nn.Sequential(\n",
    "            nn.Linear(3, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(64, 128)\n",
    "        )\n",
    "        self.conti_fc = nn.Sequential(\n",
    "            nn.Linear(15, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(64, 128)\n",
    "        )\n",
    "\n",
    "        # Fusion Layer\n",
    "        self.fusion_fc = nn.Sequential(\n",
    "            nn.Linear(128 + 128 + 128 + 128 + 128 + 128, fusion_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(fusion_dim, 128),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        # Regression Head\n",
    "        self.regressor = nn.Sequential(\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 1),  # Single output for calorie prediction\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, image, time_series_1, time_series_2, time_series_3, catagotical, continous):\n",
    "        # Process image\n",
    "        image = image.permute(0, 3, 1, 2)\n",
    "        img_feat = self.image_model(image)\n",
    "        \n",
    "        # Process time series\n",
    "        _, (time_feat_1, _) = self.lstm1(time_series_1)\n",
    "        time_feat_1 = time_feat_1[-1]  # Extract the last layer hidden state\n",
    "\n",
    "        _, (time_feat_2, _) = self.lstm2(time_series_2)\n",
    "        time_feat_2 = time_feat_2[-1]\n",
    "\n",
    "        _, (time_feat_3, _) = self.lstm1(time_series_3)\n",
    "        time_feat_3 = time_feat_3[-1]\n",
    "\n",
    "        # Process tabular data\n",
    "        cat_feat = self.cata_fc(catagotical)\n",
    "        conti_feat = self.conti_fc(continous)\n",
    "\n",
    "        # Fuse features\n",
    "        fused = torch.cat([img_feat, time_feat_1, time_feat_2, time_feat_3, cat_feat, conti_feat], dim=1)\n",
    "        fusion_out = self.fusion_fc(fused)\n",
    "\n",
    "        # Predict\n",
    "        output = self.regressor(fusion_out)\n",
    "        return output\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "8fd5e6a1-4d2e-4f61-bf19-dfa832b8a702",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MultimodalModel(\n",
    "    image_model_name=\"resnet18\",\n",
    "    fusion_dim=512\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "c1bf0652",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x24b8f1d42f0>"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "7453b34c-c48f-4b7c-a657-3987d5000a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RMSRELoss(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(RMSRELoss, self).__init__()\n",
    "\n",
    "    def forward(self, y_pred, y_true):\n",
    "        # Ensure no division by zero\n",
    "        relative_error = (y_pred - y_true) / (y_true + 1e-8)  # Add epsilon for numerical stability\n",
    "        return torch.sqrt(torch.mean(relative_error ** 2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "981116ab-0353-4f52-80be-67e376d66b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RMSRELoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(RMSRELoss, self).__init__()\n",
    "\n",
    "    def forward(self, y_pred, y_true):\n",
    "        # Compute relative error\n",
    "        relative_error = (y_pred - y_true) / (y_true + 1e-8)  # Avoid division by zero\n",
    "        # Compute RMSRE\n",
    "        rmsre = torch.sqrt(torch.mean(relative_error ** 2))\n",
    "        return rmsre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "50ba7d72-57af-4d8c-9ec5-16de5db361ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = RMSRELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001, weight_decay=1e-4)\n",
    "\n",
    "# # Train the model\n",
    "# trained_model = train_model(model, dataloaders, criterion, optimizer, num_epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "9afc397c-0fee-41ca-9f3f-76a7eaee86c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 1])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "53a0b203",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 288, 1])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minute.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "eb0c0893-86f4-4a73-a4fe-90a77219879b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/2000], Loss: 22975158.0000\n",
      "Epoch [2/2000], Loss: 21569262.0000\n",
      "Epoch [3/2000], Loss: 8431618.0000\n",
      "Epoch [4/2000], Loss: 472971.5938\n",
      "Epoch [5/2000], Loss: 529258.5000\n",
      "Epoch [6/2000], Loss: 407825.0938\n",
      "Epoch [7/2000], Loss: 5177.4097\n",
      "Epoch [8/2000], Loss: 16233.9619\n",
      "Epoch [9/2000], Loss: 2883.5010\n",
      "Epoch [10/2000], Loss: 7608.8521\n",
      "Epoch [11/2000], Loss: 10057.7207\n",
      "Epoch [12/2000], Loss: 1020.7861\n",
      "Epoch [13/2000], Loss: 320.7509\n",
      "Epoch [14/2000], Loss: 839.9681\n",
      "Epoch [15/2000], Loss: 2464.7473\n",
      "Epoch [16/2000], Loss: 387.4178\n",
      "Epoch [17/2000], Loss: 2128.6096\n",
      "Epoch [18/2000], Loss: 2665.7937\n",
      "Epoch [19/2000], Loss: 9341.4512\n",
      "Epoch [20/2000], Loss: 530.8948\n",
      "Epoch [21/2000], Loss: 677.2338\n",
      "Epoch [22/2000], Loss: 160.9490\n",
      "Epoch [23/2000], Loss: 1338.0642\n",
      "Epoch [24/2000], Loss: 822.1402\n",
      "Epoch [25/2000], Loss: 298.5852\n",
      "Epoch [26/2000], Loss: 70.1895\n",
      "Epoch [27/2000], Loss: 586.3755\n",
      "Epoch [28/2000], Loss: 320.5008\n",
      "Epoch [29/2000], Loss: 1667.8125\n",
      "Epoch [30/2000], Loss: 789.7882\n",
      "Epoch [31/2000], Loss: 45.8342\n",
      "Epoch [32/2000], Loss: 1697.5953\n",
      "Epoch [33/2000], Loss: 3013.9438\n",
      "Epoch [34/2000], Loss: 38.0034\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[92], line 14\u001b[0m\n\u001b[0;32m     11\u001b[0m label \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# print(gcm_number.shape)\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Forward pass\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(images,minute,gcm_number, Viome, categoricals, continuous)\n\u001b[0;32m     15\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, label)\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# Backward pass and optimization\u001b[39;00m\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\ML\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\ML\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[84], line 49\u001b[0m, in \u001b[0;36mMultimodalModel.forward\u001b[1;34m(self, image, time_series_1, time_series_2, time_series_3, catagotical, continous)\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, image, time_series_1, time_series_2, time_series_3, catagotical, continous):\n\u001b[0;32m     47\u001b[0m     \u001b[38;5;66;03m# Process image\u001b[39;00m\n\u001b[0;32m     48\u001b[0m     image \u001b[38;5;241m=\u001b[39m image\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m---> 49\u001b[0m     img_feat \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimage_model(image)\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;66;03m# Process time series\u001b[39;00m\n\u001b[0;32m     52\u001b[0m     _, (time_feat_1, _) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlstm1(time_series_1)\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\ML\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\ML\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\ML\\Lib\\site-packages\\torchvision\\models\\resnet.py:285\u001b[0m, in \u001b[0;36mResNet.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 285\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_impl(x)\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\ML\\Lib\\site-packages\\torchvision\\models\\resnet.py:274\u001b[0m, in \u001b[0;36mResNet._forward_impl\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    271\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmaxpool(x)\n\u001b[0;32m    273\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer1(x)\n\u001b[1;32m--> 274\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer2(x)\n\u001b[0;32m    275\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer3(x)\n\u001b[0;32m    276\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer4(x)\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\ML\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\ML\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\ML\\Lib\\site-packages\\torch\\nn\\modules\\container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m module(\u001b[38;5;28minput\u001b[39m)\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\ML\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\ML\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\ML\\Lib\\site-packages\\torchvision\\models\\resnet.py:92\u001b[0m, in \u001b[0;36mBasicBlock.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     89\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m     90\u001b[0m     identity \u001b[38;5;241m=\u001b[39m x\n\u001b[1;32m---> 92\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv1(x)\n\u001b[0;32m     93\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbn1(out)\n\u001b[0;32m     94\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu(out)\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\ML\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\ML\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\ML\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:460\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    459\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 460\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_conv_forward(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias)\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\ML\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:456\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    452\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    453\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[0;32m    454\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[0;32m    455\u001b[0m                     _pair(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[1;32m--> 456\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(\u001b[38;5;28minput\u001b[39m, weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[0;32m    457\u001b[0m                 \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_epochs = 2000\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    for data in train_loader:\n",
    "        images = data['img']\n",
    "        categoricals = data['catagorical']\n",
    "        minute = data['minute_train']\n",
    "        gcm_number = data['gcm_number_train']\n",
    "        Viome = data['Viome_train']\n",
    "        continuous = data['continuous']\n",
    "        label = data['label']\n",
    "        # print(gcm_number.shape)\n",
    "        # Forward pass\n",
    "        outputs = model(images,minute,gcm_number, Viome, categoricals, continuous)\n",
    "        loss = criterion(outputs, label)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "d463f9c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/2000], Loss: 451.3499\n",
      "Epoch [2/2000], Loss: 77.4447\n",
      "Epoch [3/2000], Loss: 54.4766\n",
      "Epoch [4/2000], Loss: 56.1421\n",
      "Epoch [5/2000], Loss: 184.8924\n",
      "Epoch [6/2000], Loss: 445.4508\n",
      "Epoch [7/2000], Loss: 13.9576\n",
      "Epoch [8/2000], Loss: 1.7376\n",
      "Epoch [9/2000], Loss: 1248.4525\n",
      "Epoch [10/2000], Loss: 589.2935\n",
      "Epoch [11/2000], Loss: 10.1756\n",
      "Epoch [12/2000], Loss: 6.3629\n",
      "Epoch [13/2000], Loss: 136.4917\n",
      "Epoch [14/2000], Loss: 7.7762\n",
      "Epoch [15/2000], Loss: 59.5650\n",
      "Epoch [16/2000], Loss: 133.0934\n",
      "Epoch [17/2000], Loss: 74.7706\n",
      "Epoch [18/2000], Loss: 27.7192\n",
      "Epoch [19/2000], Loss: 863.0573\n",
      "Epoch [20/2000], Loss: 13.5779\n",
      "Epoch [21/2000], Loss: 17.6659\n",
      "Epoch [22/2000], Loss: 12.2838\n",
      "Epoch [23/2000], Loss: 115.7188\n",
      "Epoch [24/2000], Loss: 101.0642\n",
      "Epoch [25/2000], Loss: 100.3133\n",
      "Epoch [26/2000], Loss: 313.8867\n",
      "Epoch [27/2000], Loss: 73.5765\n",
      "Epoch [28/2000], Loss: 37.7687\n",
      "Epoch [29/2000], Loss: 103.6062\n",
      "Epoch [30/2000], Loss: 29.4613\n",
      "Epoch [31/2000], Loss: 88.8393\n",
      "Epoch [32/2000], Loss: 87.8521\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[104], line 15\u001b[0m\n\u001b[0;32m     12\u001b[0m label \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# 前向传播\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(images, minute, gcm_number, Viome, categoricals, continuous)\n\u001b[0;32m     16\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, label)\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# 反向传播和优化\u001b[39;00m\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\ML\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\ML\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[84], line 49\u001b[0m, in \u001b[0;36mMultimodalModel.forward\u001b[1;34m(self, image, time_series_1, time_series_2, time_series_3, catagotical, continous)\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, image, time_series_1, time_series_2, time_series_3, catagotical, continous):\n\u001b[0;32m     47\u001b[0m     \u001b[38;5;66;03m# Process image\u001b[39;00m\n\u001b[0;32m     48\u001b[0m     image \u001b[38;5;241m=\u001b[39m image\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m---> 49\u001b[0m     img_feat \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimage_model(image)\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;66;03m# Process time series\u001b[39;00m\n\u001b[0;32m     52\u001b[0m     _, (time_feat_1, _) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlstm1(time_series_1)\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\ML\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\ML\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\ML\\Lib\\site-packages\\torchvision\\models\\resnet.py:285\u001b[0m, in \u001b[0;36mResNet.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 285\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_impl(x)\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\ML\\Lib\\site-packages\\torchvision\\models\\resnet.py:274\u001b[0m, in \u001b[0;36mResNet._forward_impl\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    271\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmaxpool(x)\n\u001b[0;32m    273\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer1(x)\n\u001b[1;32m--> 274\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer2(x)\n\u001b[0;32m    275\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer3(x)\n\u001b[0;32m    276\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer4(x)\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\ML\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\ML\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\ML\\Lib\\site-packages\\torch\\nn\\modules\\container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m module(\u001b[38;5;28minput\u001b[39m)\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\ML\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\ML\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\ML\\Lib\\site-packages\\torchvision\\models\\resnet.py:96\u001b[0m, in \u001b[0;36mBasicBlock.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     93\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbn1(out)\n\u001b[0;32m     94\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu(out)\n\u001b[1;32m---> 96\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv2(out)\n\u001b[0;32m     97\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbn2(out)\n\u001b[0;32m     99\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdownsample \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\ML\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\ML\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\ML\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:460\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    459\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 460\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_conv_forward(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias)\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\ML\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:456\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    452\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    453\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[0;32m    454\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[0;32m    455\u001b[0m                     _pair(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[1;32m--> 456\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(\u001b[38;5;28minput\u001b[39m, weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[0;32m    457\u001b[0m                 \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_epochs = 2000\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    for data in train_loader:\n",
    "        # 获取数据\n",
    "        images = data['img']\n",
    "        categoricals = data['catagorical']\n",
    "        minute = data['minute_train']\n",
    "        gcm_number = data['gcm_number_train']\n",
    "        Viome = data['Viome_train']\n",
    "        continuous = data['continuous']\n",
    "        label = data['label']\n",
    "        \n",
    "        # 前向传播\n",
    "        outputs = model(images, minute, gcm_number, Viome, categoricals, continuous)\n",
    "        loss = criterion(outputs, label)\n",
    "\n",
    "        # 反向传播和优化\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "fecc59f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 1])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "52832d6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('img', torch.Size([64, 64, 64, 3])),\n",
       " ('catagorical', torch.Size([64, 3])),\n",
       " ('minute_train', torch.Size([64, 288, 1])),\n",
       " ('gcm_number_train', torch.Size([64, 288, 1])),\n",
       " ('Viome_train', torch.Size([64, 27, 1])),\n",
       " ('continuous', torch.Size([64, 15])),\n",
       " ('label', torch.Size([64, 1]))]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(k,v.shape) for k,v in data.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "c3fada30-3a87-425b-9c80-9a57ce85bad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, test_loader):\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    \n",
    "\n",
    "    with torch.no_grad():  # Disable gradient computation for testing\n",
    "        for data in test_loader:\n",
    "            images = data['img']\n",
    "            categoricals = data['catagorical']\n",
    "            minute = data['minute_train']\n",
    "            gcm_number = data['gcm_number_train']\n",
    "            Viome = data['Viome_train']\n",
    "            continuous = data['continuous']\n",
    "            label = data['label']\n",
    "\n",
    "            # Forward pass\n",
    "    outputs = model(images,minute,gcm_number, Viome, categoricals, continuous)\n",
    "    Prediction = scaler_global.inverse_transform(outputs.detach().numpy())\n",
    "\n",
    "\n",
    "    return Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "3b871643-dfac-4682-97ba-a5b62e235f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs  = predict(model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "e71202ad-2c67-4f14-a458-e678b586b1f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[355.00058],\n",
       "       [405.09885],\n",
       "       [389.62857],\n",
       "       [404.0842 ],\n",
       "       [399.66846],\n",
       "       [393.09357],\n",
       "       [384.38818],\n",
       "       [355.00003],\n",
       "       [390.45288],\n",
       "       [355.00058],\n",
       "       [402.8714 ],\n",
       "       [355.00052],\n",
       "       [355.00046],\n",
       "       [399.49112],\n",
       "       [355.0011 ],\n",
       "       [396.65527],\n",
       "       [389.62112],\n",
       "       [355.0001 ],\n",
       "       [360.02676],\n",
       "       [404.88293],\n",
       "       [404.8348 ],\n",
       "       [377.80325],\n",
       "       [355.     ],\n",
       "       [355.00027],\n",
       "       [392.98   ],\n",
       "       [384.346  ],\n",
       "       [389.21564],\n",
       "       [355.00073],\n",
       "       [409.65445],\n",
       "       [378.1707 ],\n",
       "       [355.00046],\n",
       "       [355.0003 ],\n",
       "       [393.97733],\n",
       "       [386.7404 ],\n",
       "       [378.6148 ],\n",
       "       [404.31046],\n",
       "       [383.24164],\n",
       "       [392.65616],\n",
       "       [400.87207],\n",
       "       [355.0008 ],\n",
       "       [355.0006 ],\n",
       "       [355.00003],\n",
       "       [385.36243],\n",
       "       [389.6933 ],\n",
       "       [355.0001 ],\n",
       "       [355.     ],\n",
       "       [397.76996],\n",
       "       [355.00037],\n",
       "       [355.     ],\n",
       "       [398.7308 ],\n",
       "       [393.01236],\n",
       "       [383.58258],\n",
       "       [403.23026],\n",
       "       [355.0002 ],\n",
       "       [407.0225 ],\n",
       "       [401.32446],\n",
       "       [381.57394],\n",
       "       [396.49585],\n",
       "       [371.59024],\n",
       "       [405.6217 ],\n",
       "       [403.83575],\n",
       "       [355.00095],\n",
       "       [381.79398],\n",
       "       [387.42325]], dtype=float32)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "c7e34872-0485-4513-a745-1e9c42daf079",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Column1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>355.000580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>405.098846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>389.628571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>404.084198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>399.668457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>405.621704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>403.835754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>355.000946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>381.793976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>387.423248</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>64 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Column1\n",
       "0   355.000580\n",
       "1   405.098846\n",
       "2   389.628571\n",
       "3   404.084198\n",
       "4   399.668457\n",
       "..         ...\n",
       "59  405.621704\n",
       "60  403.835754\n",
       "61  355.000946\n",
       "62  381.793976\n",
       "63  387.423248\n",
       "\n",
       "[64 rows x 1 columns]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "b76972c7-494e-4842-82d6-a1ccb1ee1cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(outputs, columns=['Column1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "f92e77d8-a3ce-44f9-9501-f2b579cd7041",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Length of values (73) does not match length of index (64)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[99], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrow_id\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m73\u001b[39m)\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# Save to CSV\u001b[39;00m\n\u001b[0;32m      3\u001b[0m df\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmy_data.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\ML\\Lib\\site-packages\\pandas\\core\\frame.py:4311\u001b[0m, in \u001b[0;36mDataFrame.__setitem__\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   4308\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_setitem_array([key], value)\n\u001b[0;32m   4309\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   4310\u001b[0m     \u001b[38;5;66;03m# set column\u001b[39;00m\n\u001b[1;32m-> 4311\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_item(key, value)\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\ML\\Lib\\site-packages\\pandas\\core\\frame.py:4524\u001b[0m, in \u001b[0;36mDataFrame._set_item\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   4514\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_set_item\u001b[39m(\u001b[38;5;28mself\u001b[39m, key, value) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   4515\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   4516\u001b[0m \u001b[38;5;124;03m    Add series to DataFrame in specified column.\u001b[39;00m\n\u001b[0;32m   4517\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4522\u001b[0m \u001b[38;5;124;03m    ensure homogeneity.\u001b[39;00m\n\u001b[0;32m   4523\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 4524\u001b[0m     value, refs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sanitize_column(value)\n\u001b[0;32m   4526\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   4527\u001b[0m         key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\n\u001b[0;32m   4528\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m value\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   4529\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value\u001b[38;5;241m.\u001b[39mdtype, ExtensionDtype)\n\u001b[0;32m   4530\u001b[0m     ):\n\u001b[0;32m   4531\u001b[0m         \u001b[38;5;66;03m# broadcast across multiple columns if necessary\u001b[39;00m\n\u001b[0;32m   4532\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mis_unique \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns, MultiIndex):\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\ML\\Lib\\site-packages\\pandas\\core\\frame.py:5266\u001b[0m, in \u001b[0;36mDataFrame._sanitize_column\u001b[1;34m(self, value)\u001b[0m\n\u001b[0;32m   5263\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _reindex_for_setitem(value, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex)\n\u001b[0;32m   5265\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_list_like(value):\n\u001b[1;32m-> 5266\u001b[0m     com\u001b[38;5;241m.\u001b[39mrequire_length_match(value, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex)\n\u001b[0;32m   5267\u001b[0m arr \u001b[38;5;241m=\u001b[39m sanitize_array(value, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, allow_2d\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m   5268\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   5269\u001b[0m     \u001b[38;5;28misinstance\u001b[39m(value, Index)\n\u001b[0;32m   5270\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m value\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobject\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5273\u001b[0m     \u001b[38;5;66;03m# TODO: Remove kludge in sanitize_array for string mode when enforcing\u001b[39;00m\n\u001b[0;32m   5274\u001b[0m     \u001b[38;5;66;03m# this deprecation\u001b[39;00m\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\ML\\Lib\\site-packages\\pandas\\core\\common.py:573\u001b[0m, in \u001b[0;36mrequire_length_match\u001b[1;34m(data, index)\u001b[0m\n\u001b[0;32m    569\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    570\u001b[0m \u001b[38;5;124;03mCheck the length of data matches the length of the index.\u001b[39;00m\n\u001b[0;32m    571\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    572\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(index):\n\u001b[1;32m--> 573\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    574\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLength of values \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    575\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(data)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    576\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdoes not match length of index \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    577\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(index)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    578\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Length of values (73) does not match length of index (64)"
     ]
    }
   ],
   "source": [
    "df['row_id'] = range(73)\n",
    "# Save to CSV\n",
    "df.to_csv('my_data.csv', index=True)  # index=False means do not write row names (index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f94f0a4-5a73-4646-8ffb-22c8b2267bad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
