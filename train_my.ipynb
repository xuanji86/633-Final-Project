{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import ast\n",
    "from PIL import Image\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "cgm_test = pd.read_csv('633FinalData/cgm_test.csv')\n",
    "cgm_train = pd.read_csv('633FinalData/cgm_train.csv')\n",
    "img_train = pd.read_csv('633FinalData/img_train.csv')\n",
    "img_test = pd.read_csv('633FinalData/img_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "cgm_test['cgm'] = cgm_test['CGM Data'].apply(lambda x: ast.literal_eval(x))\n",
    "cgm_train['cgm'] = cgm_train['CGM Data'].apply(lambda x: ast.literal_eval(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_img(img):\n",
    "    # Convert the string representation of the image to a list\n",
    "    img = ast.literal_eval(img)\n",
    "    \n",
    "    # Convert the list to a NumPy array\n",
    "    img = np.array(img)\n",
    "    \n",
    "    # Convert the NumPy array to a PIL Image\n",
    "    img = Image.fromarray(np.uint8(img))\n",
    "    \n",
    "    # Resize the image\n",
    "    img = img.resize((64,64))\n",
    "    \n",
    "    # Convert the resized image back to a NumPy array\n",
    "    img = np.array(img)\n",
    "    \n",
    "    if len(img.shape) == 2:\n",
    "        img = np.stack((img,)*3, axis=-1)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_train['img_b'] = img_train['Image Before Breakfast'].apply(get_img)\n",
    "img_train['img_l'] = img_train['Image Before Lunch'].apply(get_img)\n",
    "img_test['img_b'] = img_test['Image Before Breakfast'].apply(get_img)\n",
    "img_test['img_l'] = img_test['Image Before Lunch'].apply(get_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_step(t):\n",
    "    date_obj = datetime.strptime(t, '%Y-%m-%d %H:%M:%S')\n",
    "    return (date_obj.hour*60 + date_obj.minute)//5\n",
    "\n",
    "def cgm_to_steps(cgm):\n",
    "    steps = [0 for _ in range(288)]\n",
    "    for t,value in cgm:\n",
    "        steps[to_step(t)] = value\n",
    "    return steps\n",
    "\n",
    "def time_to_step(t1,t2):\n",
    "    if t1 == '{}' or t2 == '{}':\n",
    "        return [0 for _ in range(288)]\n",
    "    steps = [0 for _ in range(288)]\n",
    "    steps[to_step(t1)] = 1\n",
    "    steps[to_step(t2)] = 1\n",
    "    return steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows with NaT values in 'start_time' or 'end_time'\n",
    "# cgm_test = cgm_test.dropna()\n",
    "cgm_train = cgm_train.dropna()\n",
    "# Drop rows containing the string '{}' in any column\n",
    "# cgm_test = cgm_test[~cgm_test.apply(lambda row: row.astype(str).str.contains('{}').any(), axis=1)]\n",
    "cgm_train = cgm_train[~cgm_train.apply(lambda row: row.astype(str).str.contains('{}').any(), axis=1)]\n",
    "\n",
    "cgm_test['cgm_sequential'] = cgm_test['cgm'].apply(cgm_to_steps)\n",
    "cgm_train['cgm_sequential'] = cgm_train['cgm'].apply(cgm_to_steps)\n",
    "cgm_train['when_to_eat'] = cgm_train[['Breakfast Time', 'Lunch Time']].apply(lambda x: time_to_step(x['Breakfast Time'], x['Lunch Time']), axis=1)\n",
    "cgm_test['when_to_eat'] = cgm_test[['Breakfast Time', 'Lunch Time']].apply(lambda x: time_to_step(x['Breakfast Time'], x['Lunch Time']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "viome_test = pd.read_csv('633FinalData/demo_viome_test.csv')\n",
    "viome_train = pd.read_csv('633FinalData/demo_viome_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "viome_test= pd.get_dummies(viome_test, columns=['Race'])\n",
    "viome_train= pd.get_dummies(viome_train, columns=['Race'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "viome_test['viome_sequential'] = viome_test['Viome'].apply(lambda x :[float(x) for x in x.split(',')])\n",
    "viome_train['viome_sequential'] = viome_train['Viome'].apply(lambda x :[float(x) for x in x.split(',')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_train = pd.merge(cgm_train, img_train, on=['Subject ID', 'Day'])\n",
    "combined_train = pd.merge(combined_train, viome_train, on=['Subject ID'])\n",
    "combined_test = pd.merge(cgm_test, img_test, on=['Subject ID', 'Day'])\n",
    "combined_test = pd.merge(combined_test, viome_test, on=['Subject ID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Subject ID', 'Day', 'Breakfast Time', 'Lunch Time', 'CGM Data', 'cgm',\n",
       "       'cgm_sequential', 'when_to_eat', 'Image Before Breakfast',\n",
       "       'Image Before Lunch', 'img_b', 'img_l', 'Age', 'Gender', 'Weight',\n",
       "       'Height', 'Diabetes Status', 'A1C', 'Baseline Fasting Glucose',\n",
       "       'Insulin', 'Triglycerides', 'Cholesterol', 'HDL', 'Non-HDL', 'LDL',\n",
       "       'VLDL', 'CHO/HDL Ratio', 'HOMA-IR', 'BMI', 'Viome',\n",
       "       'Race_African American', 'Race_Hispanic/Latino', 'Race_White',\n",
       "       'viome_sequential'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_drop_train = ['Subject ID','Day','Breakfast Time','Lunch Time','CGM Data','Image Before Breakfast','Image Before Lunch','Viome']\n",
    "combined_train = combined_train.drop(to_drop_train, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_drop_test = ['Subject ID','Day','Breakfast Time','Lunch Time','CGM Data','Image Before Breakfast','Image Before Lunch','Viome']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_test = combined_test.drop(to_drop_train, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['cgm', 'cgm_sequential', 'when_to_eat', 'img_b', 'img_l', 'Age',\n",
       "       'Gender', 'Weight', 'Height', 'Diabetes Status', 'A1C',\n",
       "       'Baseline Fasting Glucose', 'Insulin', 'Triglycerides', 'Cholesterol',\n",
       "       'HDL', 'Non-HDL', 'LDL', 'VLDL', 'CHO/HDL Ratio', 'HOMA-IR', 'BMI',\n",
       "       'Race_African American', 'Race_Hispanic/Latino', 'Race_White',\n",
       "       'viome_sequential'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, dataframe):\n",
    "        self.dataframe = dataframe\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.dataframe.iloc[idx]\n",
    "\n",
    "        # Extract sequential data\n",
    "        cgm_sequential = np.array(row['cgm_sequential'])\n",
    "        when_to_eat = np.array(row['when_to_eat'])\n",
    "\n",
    "        # Stack cgm_sequential and when_to_eat to create a sequential data array with 2 features\n",
    "        sequential_data = np.stack((cgm_sequential, when_to_eat), axis=-1)\n",
    "\n",
    "        sequential_data = (sequential_data - np.mean(sequential_data)) / np.std(sequential_data)\n",
    "\n",
    "        # Extract image data\n",
    "        img_b = row['img_b']\n",
    "        img_l = row['img_l']\n",
    "\n",
    "        # Convert image data to PIL Image and then to tensor\n",
    "        img_b = Image.fromarray(np.uint8(img_b))\n",
    "        img_l = Image.fromarray(np.uint8(img_l))\n",
    "\n",
    "        img_b = (img_b - np.mean(img_b)) / np.std(img_b)\n",
    "        img_l = (img_l - np.mean(img_l)) / np.std(img_l)\n",
    "\n",
    "        img_b = torch.tensor(np.array(img_b), dtype=torch.float32).permute(2, 0, 1)  # Convert to CxHxW\n",
    "        img_l = torch.tensor(np.array(img_l), dtype=torch.float32).permute(2, 0, 1)  # Convert to CxHxW\n",
    "\n",
    "        # Extract numeric data\n",
    "        numeric_data = row[['Age', 'Gender', 'Weight', 'Height', 'Diabetes Status', 'A1C',\n",
    "                            'Baseline Fasting Glucose', 'Insulin', 'Triglycerides', 'Cholesterol',\n",
    "                            'HDL', 'Non-HDL', 'LDL', 'VLDL', 'CHO/HDL Ratio', 'HOMA-IR', 'BMI',\n",
    "                            'Race_African American', 'Race_Hispanic/Latino', 'Race_White']].values.astype(np.float32)\n",
    "        numeric_data = (numeric_data - np.mean(numeric_data)) / np.std(numeric_data)\n",
    "        numeric_data = torch.tensor(numeric_data, dtype=torch.float32)\n",
    "\n",
    "        viome_sequential = np.array(row['viome_sequential']).reshape(27, 1)\n",
    "        viome_sequential = (viome_sequential - np.mean(viome_sequential)) / np.std(viome_sequential)\n",
    "\n",
    "        return {\n",
    "            'sequential_data': torch.tensor(sequential_data, dtype=torch.float32),\n",
    "            'viome_sequential': torch.tensor(viome_sequential, dtype=torch.float32),\n",
    "            'img_b': img_b,\n",
    "            'img_l': img_l,\n",
    "            'numeric_data': numeric_data\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = CustomDataset(combined_train)\n",
    "dataset_test = CustomDataset(combined_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([(64, 64, 3)], dtype=object)"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_train['img_b'].apply(lambda x: x.shape).unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 0:\n",
      "  sequential_data shape: torch.Size([288, 2])\n",
      "  viome_sequential shape: torch.Size([27, 1])\n",
      "  img_b shape: torch.Size([3, 64, 64])\n",
      "  img_l shape: torch.Size([3, 64, 64])\n",
      "  numeric_data shape: torch.Size([20])\n"
     ]
    }
   ],
   "source": [
    "for i in range(1):\n",
    "    sample = dataset_train[i]\n",
    "    print(f\"Sample {i}:\")\n",
    "    print(f\"  sequential_data shape: {sample['sequential_data'].shape}\")\n",
    "    print(f\"  viome_sequential shape: {sample['viome_sequential'].shape}\")\n",
    "    print(f\"  img_b shape: {sample['img_b'].shape}\")\n",
    "    print(f\"  img_l shape: {sample['img_l'].shape}\")\n",
    "    print(f\"  numeric_data shape: {sample['numeric_data'].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "73"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(combined_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.models as models\n",
    "\n",
    "class CombinedModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CombinedModel, self).__init__()\n",
    "        \n",
    "        # Sequential data sub-network\n",
    "        self.seq_net = nn.LSTM(input_size=2, hidden_size=64, num_layers=2, batch_first=True)\n",
    "        self.seq_fc = nn.Linear(64, 32)\n",
    "        \n",
    "        # Viome sequential data sub-network\n",
    "        self.viome_net = nn.LSTM(input_size=1, hidden_size=64, num_layers=2, batch_first=True)\n",
    "        self.viome_fc = nn.Linear(64, 32)\n",
    "        \n",
    "        # Image data sub-network using pre-trained ResNet\n",
    "        self.img_net = models.resnet18(pretrained=True)\n",
    "        self.img_net.fc = nn.Linear(self.img_net.fc.in_features, 32)  # Modify the final layer\n",
    "        \n",
    "        # Numeric data sub-network\n",
    "        self.num_net = nn.Sequential(\n",
    "            nn.Linear(20, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 16)\n",
    "        )\n",
    "        \n",
    "        # Combined fully connected layers\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(32 + 32 + 32 + 32 + 16, 64),  # Adjust input size to include both sequential outputs\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 1)  # Assuming a regression task\n",
    "        )\n",
    "    \n",
    "    def forward(self, sequential_data, img_b, img_l, numeric_data, viome_sequential):\n",
    "        # Process sequential data\n",
    "        seq_out, _ = self.seq_net(sequential_data)\n",
    "        seq_out = self.seq_fc(seq_out[:, -1, :])  # Take the last output of the LSTM and pass through a linear layer\n",
    "        \n",
    "        # Process viome sequential data\n",
    "        viome_out, _ = self.viome_net(viome_sequential)\n",
    "        viome_out = self.viome_fc(viome_out[:, -1, :])  # Take the last output of the LSTM and pass through a linear layer\n",
    "        \n",
    "        # Process image data\n",
    "        img_b_out = self.img_net(img_b)\n",
    "        img_l_out = self.img_net(img_l)\n",
    "        \n",
    "        # Process numeric data\n",
    "        num_out = self.num_net(numeric_data)\n",
    "        \n",
    "        # Concatenate all outputs\n",
    "        combined = torch.cat((seq_out, viome_out, img_b_out, img_l_out, num_out), dim=1)\n",
    "        \n",
    "        # Pass through fully connected layers\n",
    "        out = self.fc(combined)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RMSRELoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(RMSRELoss, self).__init__()\n",
    "\n",
    "    def forward(self, y_pred, y_true):\n",
    "        epsilon = 1e-6  # Small value to avoid division by zero\n",
    "        relative_error = (y_pred - y_true) / (y_true + epsilon)\n",
    "        return torch.sqrt(torch.mean(relative_error ** 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset_train, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(dataset_test, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\ML\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\ML\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "model = CombinedModel()\n",
    "criterion = RMSRELoss()  \n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\38997\\AppData\\Local\\Temp\\ipykernel_19420\\2000014717.py:28: RuntimeWarning: invalid value encountered in divide\n",
      "  img_l = (img_l - np.mean(img_l)) / np.std(img_l)\n",
      "C:\\Users\\38997\\AppData\\Local\\Temp\\ipykernel_19420\\2000014717.py:40: RuntimeWarning: invalid value encountered in cast\n",
      "  img_l = Image.fromarray(np.uint8(img_l))\n",
      "C:\\Users\\38997\\AppData\\Local\\Temp\\ipykernel_19420\\2000014717.py:28: RuntimeWarning: invalid value encountered in divide\n",
      "  img_l = (img_l - np.mean(img_l)) / np.std(img_l)\n",
      "C:\\Users\\38997\\AppData\\Local\\Temp\\ipykernel_19420\\2000014717.py:40: RuntimeWarning: invalid value encountered in cast\n",
      "  img_l = Image.fromarray(np.uint8(img_l))\n",
      "C:\\Users\\38997\\AppData\\Local\\Temp\\ipykernel_19420\\2000014717.py:27: RuntimeWarning: invalid value encountered in divide\n",
      "  img_b = (img_b - np.mean(img_b)) / np.std(img_b)\n",
      "C:\\Users\\38997\\AppData\\Local\\Temp\\ipykernel_19420\\2000014717.py:28: RuntimeWarning: invalid value encountered in divide\n",
      "  img_l = (img_l - np.mean(img_l)) / np.std(img_l)\n",
      "C:\\Users\\38997\\AppData\\Local\\Temp\\ipykernel_19420\\2000014717.py:39: RuntimeWarning: invalid value encountered in cast\n",
      "  img_b = Image.fromarray(np.uint8(img_b))\n",
      "C:\\Users\\38997\\AppData\\Local\\Temp\\ipykernel_19420\\2000014717.py:40: RuntimeWarning: invalid value encountered in cast\n",
      "  img_l = Image.fromarray(np.uint8(img_l))\n",
      "C:\\Users\\38997\\AppData\\Local\\Temp\\ipykernel_19420\\2000014717.py:28: RuntimeWarning: invalid value encountered in divide\n",
      "  img_l = (img_l - np.mean(img_l)) / np.std(img_l)\n",
      "C:\\Users\\38997\\AppData\\Local\\Temp\\ipykernel_19420\\2000014717.py:40: RuntimeWarning: invalid value encountered in cast\n",
      "  img_l = Image.fromarray(np.uint8(img_l))\n",
      "C:\\Users\\38997\\AppData\\Local\\Temp\\ipykernel_19420\\2000014717.py:27: RuntimeWarning: invalid value encountered in divide\n",
      "  img_b = (img_b - np.mean(img_b)) / np.std(img_b)\n",
      "C:\\Users\\38997\\AppData\\Local\\Temp\\ipykernel_19420\\2000014717.py:28: RuntimeWarning: invalid value encountered in divide\n",
      "  img_l = (img_l - np.mean(img_l)) / np.std(img_l)\n",
      "C:\\Users\\38997\\AppData\\Local\\Temp\\ipykernel_19420\\2000014717.py:39: RuntimeWarning: invalid value encountered in cast\n",
      "  img_b = Image.fromarray(np.uint8(img_b))\n",
      "C:\\Users\\38997\\AppData\\Local\\Temp\\ipykernel_19420\\2000014717.py:40: RuntimeWarning: invalid value encountered in cast\n",
      "  img_l = Image.fromarray(np.uint8(img_l))\n",
      "C:\\Users\\38997\\AppData\\Local\\Temp\\ipykernel_19420\\2000014717.py:16: RuntimeWarning: invalid value encountered in divide\n",
      "  cgm_sequential = (cgm_sequential - np.mean(cgm_sequential)) / np.std(cgm_sequential)\n",
      "C:\\Users\\38997\\AppData\\Local\\Temp\\ipykernel_19420\\2000014717.py:28: RuntimeWarning: invalid value encountered in divide\n",
      "  img_l = (img_l - np.mean(img_l)) / np.std(img_l)\n",
      "C:\\Users\\38997\\AppData\\Local\\Temp\\ipykernel_19420\\2000014717.py:40: RuntimeWarning: invalid value encountered in cast\n",
      "  img_l = Image.fromarray(np.uint8(img_l))\n",
      "C:\\Users\\38997\\AppData\\Local\\Temp\\ipykernel_19420\\2000014717.py:27: RuntimeWarning: invalid value encountered in divide\n",
      "  img_b = (img_b - np.mean(img_b)) / np.std(img_b)\n",
      "C:\\Users\\38997\\AppData\\Local\\Temp\\ipykernel_19420\\2000014717.py:28: RuntimeWarning: invalid value encountered in divide\n",
      "  img_l = (img_l - np.mean(img_l)) / np.std(img_l)\n",
      "C:\\Users\\38997\\AppData\\Local\\Temp\\ipykernel_19420\\2000014717.py:39: RuntimeWarning: invalid value encountered in cast\n",
      "  img_b = Image.fromarray(np.uint8(img_b))\n",
      "C:\\Users\\38997\\AppData\\Local\\Temp\\ipykernel_19420\\2000014717.py:40: RuntimeWarning: invalid value encountered in cast\n",
      "  img_l = Image.fromarray(np.uint8(img_l))\n",
      "C:\\Users\\38997\\AppData\\Local\\Temp\\ipykernel_19420\\2000014717.py:28: RuntimeWarning: invalid value encountered in divide\n",
      "  img_l = (img_l - np.mean(img_l)) / np.std(img_l)\n",
      "C:\\Users\\38997\\AppData\\Local\\Temp\\ipykernel_19420\\2000014717.py:40: RuntimeWarning: invalid value encountered in cast\n",
      "  img_l = Image.fromarray(np.uint8(img_l))\n",
      "C:\\Users\\38997\\AppData\\Local\\Temp\\ipykernel_19420\\2000014717.py:28: RuntimeWarning: invalid value encountered in divide\n",
      "  img_l = (img_l - np.mean(img_l)) / np.std(img_l)\n",
      "C:\\Users\\38997\\AppData\\Local\\Temp\\ipykernel_19420\\2000014717.py:40: RuntimeWarning: invalid value encountered in cast\n",
      "  img_l = Image.fromarray(np.uint8(img_l))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/500], Loss: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\38997\\AppData\\Local\\Temp\\ipykernel_19420\\2000014717.py:28: RuntimeWarning: invalid value encountered in divide\n",
      "  img_l = (img_l - np.mean(img_l)) / np.std(img_l)\n",
      "C:\\Users\\38997\\AppData\\Local\\Temp\\ipykernel_19420\\2000014717.py:40: RuntimeWarning: invalid value encountered in cast\n",
      "  img_l = Image.fromarray(np.uint8(img_l))\n",
      "C:\\Users\\38997\\AppData\\Local\\Temp\\ipykernel_19420\\2000014717.py:28: RuntimeWarning: invalid value encountered in divide\n",
      "  img_l = (img_l - np.mean(img_l)) / np.std(img_l)\n",
      "C:\\Users\\38997\\AppData\\Local\\Temp\\ipykernel_19420\\2000014717.py:40: RuntimeWarning: invalid value encountered in cast\n",
      "  img_l = Image.fromarray(np.uint8(img_l))\n",
      "C:\\Users\\38997\\AppData\\Local\\Temp\\ipykernel_19420\\2000014717.py:28: RuntimeWarning: invalid value encountered in divide\n",
      "  img_l = (img_l - np.mean(img_l)) / np.std(img_l)\n",
      "C:\\Users\\38997\\AppData\\Local\\Temp\\ipykernel_19420\\2000014717.py:40: RuntimeWarning: invalid value encountered in cast\n",
      "  img_l = Image.fromarray(np.uint8(img_l))\n",
      "C:\\Users\\38997\\AppData\\Local\\Temp\\ipykernel_19420\\2000014717.py:16: RuntimeWarning: invalid value encountered in divide\n",
      "  cgm_sequential = (cgm_sequential - np.mean(cgm_sequential)) / np.std(cgm_sequential)\n",
      "C:\\Users\\38997\\AppData\\Local\\Temp\\ipykernel_19420\\2000014717.py:28: RuntimeWarning: invalid value encountered in divide\n",
      "  img_l = (img_l - np.mean(img_l)) / np.std(img_l)\n",
      "C:\\Users\\38997\\AppData\\Local\\Temp\\ipykernel_19420\\2000014717.py:40: RuntimeWarning: invalid value encountered in cast\n",
      "  img_l = Image.fromarray(np.uint8(img_l))\n",
      "C:\\Users\\38997\\AppData\\Local\\Temp\\ipykernel_19420\\2000014717.py:27: RuntimeWarning: invalid value encountered in divide\n",
      "  img_b = (img_b - np.mean(img_b)) / np.std(img_b)\n",
      "C:\\Users\\38997\\AppData\\Local\\Temp\\ipykernel_19420\\2000014717.py:28: RuntimeWarning: invalid value encountered in divide\n",
      "  img_l = (img_l - np.mean(img_l)) / np.std(img_l)\n",
      "C:\\Users\\38997\\AppData\\Local\\Temp\\ipykernel_19420\\2000014717.py:39: RuntimeWarning: invalid value encountered in cast\n",
      "  img_b = Image.fromarray(np.uint8(img_b))\n",
      "C:\\Users\\38997\\AppData\\Local\\Temp\\ipykernel_19420\\2000014717.py:40: RuntimeWarning: invalid value encountered in cast\n",
      "  img_l = Image.fromarray(np.uint8(img_l))\n",
      "C:\\Users\\38997\\AppData\\Local\\Temp\\ipykernel_19420\\2000014717.py:28: RuntimeWarning: invalid value encountered in divide\n",
      "  img_l = (img_l - np.mean(img_l)) / np.std(img_l)\n",
      "C:\\Users\\38997\\AppData\\Local\\Temp\\ipykernel_19420\\2000014717.py:40: RuntimeWarning: invalid value encountered in cast\n",
      "  img_l = Image.fromarray(np.uint8(img_l))\n",
      "C:\\Users\\38997\\AppData\\Local\\Temp\\ipykernel_19420\\2000014717.py:27: RuntimeWarning: invalid value encountered in divide\n",
      "  img_b = (img_b - np.mean(img_b)) / np.std(img_b)\n",
      "C:\\Users\\38997\\AppData\\Local\\Temp\\ipykernel_19420\\2000014717.py:28: RuntimeWarning: invalid value encountered in divide\n",
      "  img_l = (img_l - np.mean(img_l)) / np.std(img_l)\n",
      "C:\\Users\\38997\\AppData\\Local\\Temp\\ipykernel_19420\\2000014717.py:39: RuntimeWarning: invalid value encountered in cast\n",
      "  img_b = Image.fromarray(np.uint8(img_b))\n",
      "C:\\Users\\38997\\AppData\\Local\\Temp\\ipykernel_19420\\2000014717.py:40: RuntimeWarning: invalid value encountered in cast\n",
      "  img_l = Image.fromarray(np.uint8(img_l))\n",
      "C:\\Users\\38997\\AppData\\Local\\Temp\\ipykernel_19420\\2000014717.py:28: RuntimeWarning: invalid value encountered in divide\n",
      "  img_l = (img_l - np.mean(img_l)) / np.std(img_l)\n",
      "C:\\Users\\38997\\AppData\\Local\\Temp\\ipykernel_19420\\2000014717.py:40: RuntimeWarning: invalid value encountered in cast\n",
      "  img_l = Image.fromarray(np.uint8(img_l))\n",
      "C:\\Users\\38997\\AppData\\Local\\Temp\\ipykernel_19420\\2000014717.py:27: RuntimeWarning: invalid value encountered in divide\n",
      "  img_b = (img_b - np.mean(img_b)) / np.std(img_b)\n",
      "C:\\Users\\38997\\AppData\\Local\\Temp\\ipykernel_19420\\2000014717.py:28: RuntimeWarning: invalid value encountered in divide\n",
      "  img_l = (img_l - np.mean(img_l)) / np.std(img_l)\n",
      "C:\\Users\\38997\\AppData\\Local\\Temp\\ipykernel_19420\\2000014717.py:39: RuntimeWarning: invalid value encountered in cast\n",
      "  img_b = Image.fromarray(np.uint8(img_b))\n",
      "C:\\Users\\38997\\AppData\\Local\\Temp\\ipykernel_19420\\2000014717.py:40: RuntimeWarning: invalid value encountered in cast\n",
      "  img_l = Image.fromarray(np.uint8(img_l))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/500], Loss: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\38997\\AppData\\Local\\Temp\\ipykernel_19420\\2000014717.py:28: RuntimeWarning: invalid value encountered in divide\n",
      "  img_l = (img_l - np.mean(img_l)) / np.std(img_l)\n",
      "C:\\Users\\38997\\AppData\\Local\\Temp\\ipykernel_19420\\2000014717.py:40: RuntimeWarning: invalid value encountered in cast\n",
      "  img_l = Image.fromarray(np.uint8(img_l))\n",
      "C:\\Users\\38997\\AppData\\Local\\Temp\\ipykernel_19420\\2000014717.py:16: RuntimeWarning: invalid value encountered in divide\n",
      "  cgm_sequential = (cgm_sequential - np.mean(cgm_sequential)) / np.std(cgm_sequential)\n",
      "C:\\Users\\38997\\AppData\\Local\\Temp\\ipykernel_19420\\2000014717.py:28: RuntimeWarning: invalid value encountered in divide\n",
      "  img_l = (img_l - np.mean(img_l)) / np.std(img_l)\n",
      "C:\\Users\\38997\\AppData\\Local\\Temp\\ipykernel_19420\\2000014717.py:40: RuntimeWarning: invalid value encountered in cast\n",
      "  img_l = Image.fromarray(np.uint8(img_l))\n",
      "C:\\Users\\38997\\AppData\\Local\\Temp\\ipykernel_19420\\2000014717.py:27: RuntimeWarning: invalid value encountered in divide\n",
      "  img_b = (img_b - np.mean(img_b)) / np.std(img_b)\n",
      "C:\\Users\\38997\\AppData\\Local\\Temp\\ipykernel_19420\\2000014717.py:28: RuntimeWarning: invalid value encountered in divide\n",
      "  img_l = (img_l - np.mean(img_l)) / np.std(img_l)\n",
      "C:\\Users\\38997\\AppData\\Local\\Temp\\ipykernel_19420\\2000014717.py:39: RuntimeWarning: invalid value encountered in cast\n",
      "  img_b = Image.fromarray(np.uint8(img_b))\n",
      "C:\\Users\\38997\\AppData\\Local\\Temp\\ipykernel_19420\\2000014717.py:40: RuntimeWarning: invalid value encountered in cast\n",
      "  img_l = Image.fromarray(np.uint8(img_l))\n",
      "C:\\Users\\38997\\AppData\\Local\\Temp\\ipykernel_19420\\2000014717.py:28: RuntimeWarning: invalid value encountered in divide\n",
      "  img_l = (img_l - np.mean(img_l)) / np.std(img_l)\n",
      "C:\\Users\\38997\\AppData\\Local\\Temp\\ipykernel_19420\\2000014717.py:40: RuntimeWarning: invalid value encountered in cast\n",
      "  img_l = Image.fromarray(np.uint8(img_l))\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[222], line 19\u001b[0m\n\u001b[0;32m     17\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m     18\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m---> 19\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m     21\u001b[0m     running_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_epochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m], Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrunning_loss\u001b[38;5;241m/\u001b[39m\u001b[38;5;28mlen\u001b[39m(train_loader)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\ML\\Lib\\site-packages\\torch\\optim\\optimizer.py:391\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    386\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    387\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    388\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    389\u001b[0m             )\n\u001b[1;32m--> 391\u001b[0m out \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    392\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[0;32m    394\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\ML\\Lib\\site-packages\\torch\\optim\\optimizer.py:76\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     74\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefaults[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     75\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n\u001b[1;32m---> 76\u001b[0m     ret \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     77\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     78\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\ML\\Lib\\site-packages\\torch\\optim\\adam.py:168\u001b[0m, in \u001b[0;36mAdam.step\u001b[1;34m(self, closure)\u001b[0m\n\u001b[0;32m    157\u001b[0m     beta1, beta2 \u001b[38;5;241m=\u001b[39m group[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbetas\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m    159\u001b[0m     has_complex \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_group(\n\u001b[0;32m    160\u001b[0m         group,\n\u001b[0;32m    161\u001b[0m         params_with_grad,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    165\u001b[0m         max_exp_avg_sqs,\n\u001b[0;32m    166\u001b[0m         state_steps)\n\u001b[1;32m--> 168\u001b[0m     adam(\n\u001b[0;32m    169\u001b[0m         params_with_grad,\n\u001b[0;32m    170\u001b[0m         grads,\n\u001b[0;32m    171\u001b[0m         exp_avgs,\n\u001b[0;32m    172\u001b[0m         exp_avg_sqs,\n\u001b[0;32m    173\u001b[0m         max_exp_avg_sqs,\n\u001b[0;32m    174\u001b[0m         state_steps,\n\u001b[0;32m    175\u001b[0m         amsgrad\u001b[38;5;241m=\u001b[39mgroup[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mamsgrad\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m    176\u001b[0m         has_complex\u001b[38;5;241m=\u001b[39mhas_complex,\n\u001b[0;32m    177\u001b[0m         beta1\u001b[38;5;241m=\u001b[39mbeta1,\n\u001b[0;32m    178\u001b[0m         beta2\u001b[38;5;241m=\u001b[39mbeta2,\n\u001b[0;32m    179\u001b[0m         lr\u001b[38;5;241m=\u001b[39mgroup[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlr\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m    180\u001b[0m         weight_decay\u001b[38;5;241m=\u001b[39mgroup[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mweight_decay\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m    181\u001b[0m         eps\u001b[38;5;241m=\u001b[39mgroup[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124meps\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m    182\u001b[0m         maximize\u001b[38;5;241m=\u001b[39mgroup[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmaximize\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m    183\u001b[0m         foreach\u001b[38;5;241m=\u001b[39mgroup[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mforeach\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m    184\u001b[0m         capturable\u001b[38;5;241m=\u001b[39mgroup[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcapturable\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m    185\u001b[0m         differentiable\u001b[38;5;241m=\u001b[39mgroup[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m    186\u001b[0m         fused\u001b[38;5;241m=\u001b[39mgroup[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfused\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m    187\u001b[0m         grad_scale\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgrad_scale\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m    188\u001b[0m         found_inf\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfound_inf\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m    189\u001b[0m     )\n\u001b[0;32m    191\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\ML\\Lib\\site-packages\\torch\\optim\\adam.py:318\u001b[0m, in \u001b[0;36madam\u001b[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, has_complex, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[0;32m    315\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    316\u001b[0m     func \u001b[38;5;241m=\u001b[39m _single_tensor_adam\n\u001b[1;32m--> 318\u001b[0m func(params,\n\u001b[0;32m    319\u001b[0m      grads,\n\u001b[0;32m    320\u001b[0m      exp_avgs,\n\u001b[0;32m    321\u001b[0m      exp_avg_sqs,\n\u001b[0;32m    322\u001b[0m      max_exp_avg_sqs,\n\u001b[0;32m    323\u001b[0m      state_steps,\n\u001b[0;32m    324\u001b[0m      amsgrad\u001b[38;5;241m=\u001b[39mamsgrad,\n\u001b[0;32m    325\u001b[0m      has_complex\u001b[38;5;241m=\u001b[39mhas_complex,\n\u001b[0;32m    326\u001b[0m      beta1\u001b[38;5;241m=\u001b[39mbeta1,\n\u001b[0;32m    327\u001b[0m      beta2\u001b[38;5;241m=\u001b[39mbeta2,\n\u001b[0;32m    328\u001b[0m      lr\u001b[38;5;241m=\u001b[39mlr,\n\u001b[0;32m    329\u001b[0m      weight_decay\u001b[38;5;241m=\u001b[39mweight_decay,\n\u001b[0;32m    330\u001b[0m      eps\u001b[38;5;241m=\u001b[39meps,\n\u001b[0;32m    331\u001b[0m      maximize\u001b[38;5;241m=\u001b[39mmaximize,\n\u001b[0;32m    332\u001b[0m      capturable\u001b[38;5;241m=\u001b[39mcapturable,\n\u001b[0;32m    333\u001b[0m      differentiable\u001b[38;5;241m=\u001b[39mdifferentiable,\n\u001b[0;32m    334\u001b[0m      grad_scale\u001b[38;5;241m=\u001b[39mgrad_scale,\n\u001b[0;32m    335\u001b[0m      found_inf\u001b[38;5;241m=\u001b[39mfound_inf)\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\ML\\Lib\\site-packages\\torch\\optim\\adam.py:393\u001b[0m, in \u001b[0;36m_single_tensor_adam\u001b[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, has_complex, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[0m\n\u001b[0;32m    390\u001b[0m     param \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mview_as_real(param)\n\u001b[0;32m    392\u001b[0m \u001b[38;5;66;03m# Decay the first and second moment running average coefficient\u001b[39;00m\n\u001b[1;32m--> 393\u001b[0m exp_avg\u001b[38;5;241m.\u001b[39mlerp_(grad, \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m beta1)\n\u001b[0;32m    394\u001b[0m exp_avg_sq\u001b[38;5;241m.\u001b[39mmul_(beta2)\u001b[38;5;241m.\u001b[39maddcmul_(grad, grad\u001b[38;5;241m.\u001b[39mconj(), value\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m beta2)\n\u001b[0;32m    396\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m capturable \u001b[38;5;129;01mor\u001b[39;00m differentiable:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_epochs = 500\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for batch in train_loader:\n",
    "        sequential_data = batch['sequential_data']\n",
    "        img_b = batch['img_b']\n",
    "        img_l = batch['img_l']\n",
    "        numeric_data = batch['numeric_data']\n",
    "        viome_sequential = batch['viome_sequential']\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(sequential_data, img_b, img_l, numeric_data, viome_sequential)\n",
    "        loss = criterion(outputs, torch.zeros_like(outputs))  # Replace with actual target values\n",
    "        \n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader)}\")\n",
    "\n",
    "print(\"Training complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
