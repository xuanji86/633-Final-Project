{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import ast\n",
    "from PIL import Image\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "cgm_test = pd.read_csv('633FinalData/cgm_test.csv')\n",
    "cgm_train = pd.read_csv('633FinalData/cgm_train.csv')\n",
    "img_train = pd.read_csv('633FinalData/img_train.csv')\n",
    "img_test = pd.read_csv('633FinalData/img_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "cgm_test['cgm'] = cgm_test['CGM Data'].apply(lambda x: ast.literal_eval(x))\n",
    "cgm_train['cgm'] = cgm_train['CGM Data'].apply(lambda x: ast.literal_eval(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_img(img):\n",
    "    # Convert the string representation of the image to a list\n",
    "    img = ast.literal_eval(img)\n",
    "    \n",
    "    # Convert the list to a NumPy array\n",
    "    img = np.array(img)\n",
    "    \n",
    "    # Convert the NumPy array to a PIL Image\n",
    "    img = Image.fromarray(np.uint8(img))\n",
    "    \n",
    "    # Resize the image\n",
    "    img = img.resize((64,64))\n",
    "    \n",
    "    # Convert the resized image back to a NumPy array\n",
    "    img = np.array(img)\n",
    "    \n",
    "    if len(img.shape) == 2:\n",
    "        img = np.stack((img,)*3, axis=-1)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_train['img_b'] = img_train['Image Before Breakfast'].apply(get_img)\n",
    "img_train['img_l'] = img_train['Image Before Lunch'].apply(get_img)\n",
    "img_test['img_b'] = img_test['Image Before Breakfast'].apply(get_img)\n",
    "img_test['img_l'] = img_test['Image Before Lunch'].apply(get_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_step(t):\n",
    "    date_obj = datetime.strptime(t, '%Y-%m-%d %H:%M:%S')\n",
    "    return (date_obj.hour*60 + date_obj.minute)//5\n",
    "\n",
    "def cgm_to_steps(cgm):\n",
    "    steps = [0 for _ in range(288)]\n",
    "    for t,value in cgm:\n",
    "        steps[to_step(t)] = value\n",
    "    return steps\n",
    "\n",
    "def time_to_step(t1,t2):\n",
    "    if t1 == '{}' or t2 == '{}':\n",
    "        return [0 for _ in range(288)]\n",
    "    steps = [0 for _ in range(288)]\n",
    "    steps[to_step(t1)] = 1\n",
    "    steps[to_step(t2)] = 1\n",
    "    return steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows with NaT values in 'start_time' or 'end_time'\n",
    "# cgm_test = cgm_test.dropna()\n",
    "cgm_train = cgm_train.dropna()\n",
    "# Drop rows containing the string '{}' in any column\n",
    "# cgm_test = cgm_test[~cgm_test.apply(lambda row: row.astype(str).str.contains('{}').any(), axis=1)]\n",
    "cgm_train = cgm_train[~cgm_train.apply(lambda row: row.astype(str).str.contains('{}').any(), axis=1)]\n",
    "\n",
    "cgm_test['cgm_sequential'] = cgm_test['cgm'].apply(cgm_to_steps)\n",
    "cgm_train['cgm_sequential'] = cgm_train['cgm'].apply(cgm_to_steps)\n",
    "cgm_train['when_to_eat'] = cgm_train[['Breakfast Time', 'Lunch Time']].apply(lambda x: time_to_step(x['Breakfast Time'], x['Lunch Time']), axis=1)\n",
    "cgm_test['when_to_eat'] = cgm_test[['Breakfast Time', 'Lunch Time']].apply(lambda x: time_to_step(x['Breakfast Time'], x['Lunch Time']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "viome_test = pd.read_csv('633FinalData/demo_viome_test.csv')\n",
    "viome_train = pd.read_csv('633FinalData/demo_viome_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "viome_test= pd.get_dummies(viome_test, columns=['Race'])\n",
    "viome_train= pd.get_dummies(viome_train, columns=['Race'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "viome_test['viome_sequential'] = viome_test['Viome'].apply(lambda x :[float(x) for x in x.split(',')])\n",
    "viome_train['viome_sequential'] = viome_train['Viome'].apply(lambda x :[float(x) for x in x.split(',')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_train = pd.merge(cgm_train, img_train, on=['Subject ID', 'Day'])\n",
    "combined_train = pd.merge(combined_train, viome_train, on=['Subject ID'])\n",
    "combined_test = pd.merge(cgm_test, img_test, on=['Subject ID', 'Day'])\n",
    "combined_test = pd.merge(combined_test, viome_test, on=['Subject ID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Subject ID', 'Day', 'Breakfast Time', 'Lunch Time', 'CGM Data', 'cgm',\n",
       "       'cgm_sequential', 'when_to_eat', 'Image Before Breakfast',\n",
       "       'Image Before Lunch', 'img_b', 'img_l', 'Age', 'Gender', 'Weight',\n",
       "       'Height', 'Diabetes Status', 'A1C', 'Baseline Fasting Glucose',\n",
       "       'Insulin', 'Triglycerides', 'Cholesterol', 'HDL', 'Non-HDL', 'LDL',\n",
       "       'VLDL', 'CHO/HDL Ratio', 'HOMA-IR', 'BMI', 'Viome',\n",
       "       'Race_African American', 'Race_Hispanic/Latino', 'Race_White',\n",
       "       'viome_sequential'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_drop_train = ['Subject ID','Day','Breakfast Time','Lunch Time','CGM Data','Image Before Breakfast','Image Before Lunch','Viome']\n",
    "combined_train = combined_train.drop(to_drop_train, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_drop_test = ['Subject ID','Day','Breakfast Time','Lunch Time','CGM Data','Image Before Breakfast','Image Before Lunch','Viome']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_test = combined_test.drop(to_drop_train, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_train = pd.read_csv('633FinalData/label_train.csv')\n",
    "label_train = label_train['Lunch Calories']\n",
    "combined_train['label'] = label_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, dataframe):\n",
    "        self.dataframe = dataframe\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.dataframe.iloc[idx]\n",
    "\n",
    "        # Small epsilon value to avoid division by zero\n",
    "        epsilon = 1e-6\n",
    "\n",
    "        # Extract sequential data\n",
    "        cgm_sequential = np.array(row['cgm_sequential'], dtype=float)\n",
    "        when_to_eat = np.array(row['when_to_eat'], dtype=float)\n",
    "\n",
    "        # Normalize sequential data\n",
    "        cgm_sequential = (cgm_sequential - np.mean(cgm_sequential)) / (np.std(cgm_sequential) + epsilon)\n",
    "        when_to_eat = (when_to_eat - np.mean(when_to_eat)) / (np.std(when_to_eat) + epsilon)\n",
    "\n",
    "        # Stack cgm_sequential and when_to_eat to create a sequential data array with 2 features\n",
    "        sequential_data = np.stack((cgm_sequential, when_to_eat), axis=-1)\n",
    "\n",
    "        # Extract image data\n",
    "        img_b = np.array(row['img_b'], dtype=float)\n",
    "        img_l = np.array(row['img_l'], dtype=float)\n",
    "\n",
    "        # Normalize image data\n",
    "        img_b = (img_b - np.mean(img_b)) / (np.std(img_b) + epsilon)\n",
    "        img_l = (img_l - np.mean(img_l)) / (np.std(img_l) + epsilon)\n",
    "\n",
    "        # Ensure img_b has 3 channels\n",
    "        if img_b.ndim == 2:  # Grayscale image\n",
    "            img_b = np.stack((img_b, img_b, img_b), axis=-1)\n",
    "\n",
    "        # Ensure img_l has 3 channels\n",
    "        if img_l.ndim == 2:  # Grayscale image\n",
    "            img_l = np.stack((img_l, img_l, img_l), axis=-1)\n",
    "\n",
    "        # Convert image data to PIL Image and then to tensor\n",
    "        img_b = Image.fromarray(np.uint8(img_b))\n",
    "        img_l = Image.fromarray(np.uint8(img_l))\n",
    "        img_b = torch.tensor(np.array(img_b), dtype=torch.float32).permute(2, 0, 1)  # Convert to CxHxW\n",
    "        img_l = torch.tensor(np.array(img_l), dtype=torch.float32).permute(2, 0, 1)  # Convert to CxHxW\n",
    "\n",
    "        # Extract numeric data\n",
    "        numeric_data = row[['Age', 'Gender', 'Weight', 'Height', 'Diabetes Status', 'A1C',\n",
    "                            'Baseline Fasting Glucose', 'Insulin', 'Triglycerides', 'Cholesterol',\n",
    "                            'HDL', 'Non-HDL', 'LDL', 'VLDL', 'CHO/HDL Ratio', 'HOMA-IR', 'BMI',\n",
    "                            'Race_African American', 'Race_Hispanic/Latino', 'Race_White']].values.astype(np.float32)\n",
    "\n",
    "        # Normalize numeric data\n",
    "        numeric_data = (numeric_data - np.mean(numeric_data)) / (np.std(numeric_data) + epsilon)\n",
    "        numeric_data = torch.tensor(numeric_data, dtype=torch.float32)\n",
    "\n",
    "        # Extract and reshape viome_sequential\n",
    "        viome_sequential = np.array(row['viome_sequential'], dtype=float).reshape(27, 1)\n",
    "\n",
    "        # Normalize viome_sequential\n",
    "        viome_sequential = (viome_sequential - np.mean(viome_sequential)) / (np.std(viome_sequential) + epsilon)\n",
    "\n",
    "        label_train = row['label']\n",
    "\n",
    "        return {\n",
    "            'sequential_data': torch.tensor(sequential_data, dtype=torch.float32),\n",
    "            'viome_sequential': torch.tensor(viome_sequential, dtype=torch.float32),\n",
    "            'img_b': img_b,\n",
    "            'img_l': img_l,\n",
    "            'numeric_data': numeric_data,\n",
    "            'label': label_train\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomTestDataset(Dataset):\n",
    "    def __init__(self, dataframe):\n",
    "        self.dataframe = dataframe\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.dataframe.iloc[idx]\n",
    "\n",
    "        # Small epsilon value to avoid division by zero\n",
    "        epsilon = 1e-6\n",
    "\n",
    "        # Extract sequential data\n",
    "        cgm_sequential = np.array(row['cgm_sequential'], dtype=float)\n",
    "        when_to_eat = np.array(row['when_to_eat'], dtype=float)\n",
    "\n",
    "        # Normalize sequential data\n",
    "        cgm_sequential = (cgm_sequential - np.mean(cgm_sequential)) / (np.std(cgm_sequential) + epsilon)\n",
    "        when_to_eat = (when_to_eat - np.mean(when_to_eat)) / (np.std(when_to_eat) + epsilon)\n",
    "\n",
    "        # Stack cgm_sequential and when_to_eat to create a sequential data array with 2 features\n",
    "        sequential_data = np.stack((cgm_sequential, when_to_eat), axis=-1)\n",
    "\n",
    "        # Extract image data\n",
    "        img_b = np.array(row['img_b'], dtype=float)\n",
    "        img_l = np.array(row['img_l'], dtype=float)\n",
    "\n",
    "        # Normalize image data\n",
    "        img_b = (img_b - np.mean(img_b)) / (np.std(img_b) + epsilon)\n",
    "        img_l = (img_l - np.mean(img_l)) / (np.std(img_l) + epsilon)\n",
    "\n",
    "        # Ensure img_b has 3 channels\n",
    "        if img_b.ndim == 2:  # Grayscale image\n",
    "            img_b = np.stack((img_b, img_b, img_b), axis=-1)\n",
    "\n",
    "        # Ensure img_l has 3 channels\n",
    "        if img_l.ndim == 2:  # Grayscale image\n",
    "            img_l = np.stack((img_l, img_l, img_l), axis=-1)\n",
    "\n",
    "        # Convert image data to PIL Image and then to tensor\n",
    "        img_b = Image.fromarray(np.uint8(img_b))\n",
    "        img_l = Image.fromarray(np.uint8(img_l))\n",
    "        img_b = torch.tensor(np.array(img_b), dtype=torch.float32).permute(2, 0, 1)  # Convert to CxHxW\n",
    "        img_l = torch.tensor(np.array(img_l), dtype=torch.float32).permute(2, 0, 1)  # Convert to CxHxW\n",
    "\n",
    "        # Extract numeric data\n",
    "        numeric_data = row[['Age', 'Gender', 'Weight', 'Height', 'Diabetes Status', 'A1C',\n",
    "                            'Baseline Fasting Glucose', 'Insulin', 'Triglycerides', 'Cholesterol',\n",
    "                            'HDL', 'Non-HDL', 'LDL', 'VLDL', 'CHO/HDL Ratio', 'HOMA-IR', 'BMI',\n",
    "                            'Race_African American', 'Race_Hispanic/Latino', 'Race_White']].values.astype(np.float32)\n",
    "\n",
    "        # Normalize numeric data\n",
    "        numeric_data = (numeric_data - np.mean(numeric_data)) / (np.std(numeric_data) + epsilon)\n",
    "        numeric_data = torch.tensor(numeric_data, dtype=torch.float32)\n",
    "\n",
    "        # Extract and reshape viome_sequential\n",
    "        viome_sequential = np.array(row['viome_sequential'], dtype=float).reshape(27, 1)\n",
    "\n",
    "        # Normalize viome_sequential\n",
    "        viome_sequential = (viome_sequential - np.mean(viome_sequential)) / (np.std(viome_sequential) + epsilon)\n",
    "\n",
    "\n",
    "        return {\n",
    "            'sequential_data': torch.tensor(sequential_data, dtype=torch.float32),\n",
    "            'viome_sequential': torch.tensor(viome_sequential, dtype=torch.float32),\n",
    "            'img_b': img_b,\n",
    "            'img_l': img_l,\n",
    "            'numeric_data': numeric_data,\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = CustomDataset(combined_train)\n",
    "dataset_test = CustomTestDataset(combined_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([(64, 64, 3)], dtype=object)"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_train['img_b'].apply(lambda x: x.shape).unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 0:\n",
      "  sequential_data shape: torch.Size([288, 2])\n",
      "  viome_sequential shape: torch.Size([27, 1])\n",
      "  img_b shape: torch.Size([3, 64, 64])\n",
      "  img_l shape: torch.Size([3, 64, 64])\n",
      "  numeric_data shape: torch.Size([20])\n",
      "  label: 830\n"
     ]
    }
   ],
   "source": [
    "for i in range(1):\n",
    "    sample = dataset_train[i]\n",
    "    print(f\"Sample {i}:\")\n",
    "    print(f\"  sequential_data shape: {sample['sequential_data'].shape}\")\n",
    "    print(f\"  viome_sequential shape: {sample['viome_sequential'].shape}\")\n",
    "    print(f\"  img_b shape: {sample['img_b'].shape}\")\n",
    "    print(f\"  img_l shape: {sample['img_l'].shape}\")\n",
    "    print(f\"  numeric_data shape: {sample['numeric_data'].shape}\")\n",
    "    print(f\"  label: {sample['label']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "73"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(combined_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.models as models\n",
    "\n",
    "class CombinedModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CombinedModel, self).__init__()\n",
    "        \n",
    "        # Sequential data sub-network\n",
    "        self.seq_net = nn.LSTM(input_size=2, hidden_size=64, num_layers=2, batch_first=True)\n",
    "        self.seq_fc = nn.Linear(64, 32)\n",
    "        \n",
    "        # Viome sequential data sub-network\n",
    "        self.viome_net = nn.LSTM(input_size=1, hidden_size=64, num_layers=2, batch_first=True)\n",
    "        self.viome_fc = nn.Linear(64, 32)\n",
    "        \n",
    "        # Image data sub-network using pre-trained ResNet\n",
    "        self.img_net = models.resnet50(pretrained=False)\n",
    "        self.img_net.fc = nn.Linear(self.img_net.fc.in_features, 32)  # Modify the final layer\n",
    "        \n",
    "        # Numeric data sub-network\n",
    "        self.num_net = nn.Sequential(\n",
    "            nn.Linear(20, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 16)\n",
    "        )\n",
    "        \n",
    "        # Combined fully connected layers\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(32 + 32 + 32 + 32 + 16, 64),  # Adjust input size to include both sequential outputs\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 1)  # Assuming a regression task\n",
    "        )\n",
    "    \n",
    "    def forward(self, sequential_data, img_b, img_l, numeric_data, viome_sequential):\n",
    "        # Process sequential data\n",
    "        seq_out, _ = self.seq_net(sequential_data)\n",
    "        seq_out = self.seq_fc(seq_out[:, -1, :])  # Take the last output of the LSTM and pass through a linear layer\n",
    "        \n",
    "        # Process viome sequential data\n",
    "        viome_out, _ = self.viome_net(viome_sequential)\n",
    "        viome_out = self.viome_fc(viome_out[:, -1, :])  # Take the last output of the LSTM and pass through a linear layer\n",
    "        \n",
    "        # Process image data\n",
    "        img_b_out = self.img_net(img_b)\n",
    "        img_l_out = self.img_net(img_l)\n",
    "        \n",
    "        # Process numeric data\n",
    "        num_out = self.num_net(numeric_data)\n",
    "        \n",
    "        # Concatenate all outputs\n",
    "        combined = torch.cat((seq_out, viome_out, img_b_out, img_l_out, num_out), dim=1)\n",
    "        \n",
    "        # Pass through fully connected layers\n",
    "        out = self.fc(combined)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RMSRELoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(RMSRELoss, self).__init__()\n",
    "\n",
    "    def forward(self, y_pred, y_true):\n",
    "        epsilon = 1e-6  # Small value to avoid division by zero\n",
    "        relative_error = (y_pred - y_true) / (y_true + epsilon)\n",
    "        return torch.sqrt(torch.mean(relative_error ** 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset_train, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(dataset_test, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\ML\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\ML\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "model = CombinedModel()\n",
    "criterion = RMSRELoss()  \n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)  # Reduced learning rate\n",
    "\n",
    "# Learning rate scheduler\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=50, gamma=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/500], Loss: 0.9843496547804939\n",
      "Epoch [2/500], Loss: 0.8696717421213785\n",
      "Epoch [3/500], Loss: 0.5713232788774703\n",
      "Epoch [4/500], Loss: 0.36822982960277134\n",
      "Epoch [5/500], Loss: 0.3413766258292728\n",
      "Epoch [6/500], Loss: 0.33532317810588413\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[303], line 19\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# Backward pass and optimization\u001b[39;00m\n\u001b[0;32m     18\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m---> 19\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m     20\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m     22\u001b[0m running_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\ML\\Lib\\site-packages\\torch\\_tensor.py:525\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    515\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    517\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    518\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    523\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    524\u001b[0m     )\n\u001b[1;32m--> 525\u001b[0m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mbackward(\n\u001b[0;32m    526\u001b[0m     \u001b[38;5;28mself\u001b[39m, gradient, retain_graph, create_graph, inputs\u001b[38;5;241m=\u001b[39minputs\n\u001b[0;32m    527\u001b[0m )\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\ML\\Lib\\site-packages\\torch\\autograd\\__init__.py:267\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    262\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    264\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    265\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    266\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 267\u001b[0m _engine_run_backward(\n\u001b[0;32m    268\u001b[0m     tensors,\n\u001b[0;32m    269\u001b[0m     grad_tensors_,\n\u001b[0;32m    270\u001b[0m     retain_graph,\n\u001b[0;32m    271\u001b[0m     create_graph,\n\u001b[0;32m    272\u001b[0m     inputs,\n\u001b[0;32m    273\u001b[0m     allow_unreachable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    274\u001b[0m     accumulate_grad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    275\u001b[0m )\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\ML\\Lib\\site-packages\\torch\\autograd\\graph.py:744\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[1;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    742\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[0;32m    743\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 744\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Variable\u001b[38;5;241m.\u001b[39m_execution_engine\u001b[38;5;241m.\u001b[39mrun_backward(  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    745\u001b[0m         t_outputs, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    746\u001b[0m     )  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    747\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    748\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_epochs = 500\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for batch in train_loader:\n",
    "        sequential_data = batch['sequential_data']\n",
    "        img_b = batch['img_b']\n",
    "        img_l = batch['img_l']\n",
    "        numeric_data = batch['numeric_data']\n",
    "        viome_sequential = batch['viome_sequential']\n",
    "        label = batch['label']\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(sequential_data, img_b, img_l, numeric_data, viome_sequential)\n",
    "        loss = criterion(outputs,label )  # Replace with actual target values\n",
    "        \n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "    scheduler.step()\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader)}\")\n",
    "\n",
    "print(\"Training complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "test_loss = 0.0\n",
    "all_outputs = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():  # Disable gradient calculation\n",
    "    for batch in test_loader:\n",
    "        sequential_data = batch['sequential_data']\n",
    "        img_b = batch['img_b']\n",
    "        img_l = batch['img_l']\n",
    "        numeric_data = batch['numeric_data']\n",
    "        viome_sequential = batch['viome_sequential']\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(sequential_data, img_b, img_l, numeric_data, viome_sequential)\n",
    "        \n",
    "        all_outputs+=([i[0] for i in outputs.tolist()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions saved to 'submission.csv' in Kaggle format.\n"
     ]
    }
   ],
   "source": [
    "test_ids = np.arange(len(all_outputs))  # row_id 从 0 开始，按顺序生成\n",
    "submission = pd.DataFrame({\"row_id\": test_ids, \"label\": all_outputs})\n",
    "submission.to_csv(\"submission.csv\", index=False)\n",
    "print(\"Predictions saved to 'submission.csv' in Kaggle format.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 555,  355,  555,  435,  435,  355,  830,  555,  830,  355,  435,  555,\n",
       "         355,  355,  830,  555,  555,  355,  435, 1180,  830,  830,  355,  555,\n",
       "         830,  355,  830,  435,  435,  435,  555,  555])"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
